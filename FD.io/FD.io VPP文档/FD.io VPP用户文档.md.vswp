vnote_backup_file_826537664 E:/学习文档/FD.io/FD.io VPP文档/FD.io VPP用户文档.md
<div align=center>
	<img src="_v_images/20200904171558212_22234.png" width="300"> 
</div>

<br/>
<br/>
<br/>

<center><font size='20'>FD.io VPP：用户文档</font></center>
<br/>
<br/>
<center><font size='5'>荣涛</font></center>
<center><font size='5'>2020年9月</font></center>
<br/>
<br/>
<br/>
<br/>


[What is the Vector Packet Processor](https://fd.io/docs/vpp/master/#)



<br/>


# 1. 什么是向量包处理器（VPP）

FD.io的矢量包处理器（VPP）是一个快速，可扩展的`2-4层`多平台网络协议栈。它在Linux用户空间中的多种体系结构上运行，包括`x86，ARM和Power`体系结构。

VPP的高性能网络协议栈正迅速成为全球应用程序选择的网络协议栈。

通过广泛使用`插件`，VPP不断得到增强。该 `数据平面开发套件（DPDK）` 就是一个很好的例子。它提供了VPP的一些重要功能和驱动程序。**（DPDK在VPP看来是一个插件）**

**VPP支持与OpenStack和Kubernetes集成**。网络管理功能包括配置，计数器，采样等。对于开发人员来说，VPP包括高性能的事件记录和多种数据包跟踪。开发调试映像包括完整的符号表和广泛的一致性检查。

一些VPP用例包括vSwitch，vRouter，网关，防火墙和负载均衡器，仅举几例。

**`Should be MORE`**

<br/>

# 2. 向量包处理器（VPP）

本节介绍了FD.io VPP的一些核心概念和功能。

从FD.io开始，VPP使用了一种称为`矢量包处理`的技术。与使用标量处理的数据包处理应用程序相比，这使FD.io VPP的性能有了显着提高。

同样，Fd.io VPP**模块化设计**的核心是“**`数据包处理图`**”。**这使FD.io VPP可扩展且易于扩展**。

FD.io软件还包括功能丰富的网络协议栈。这包括一个利用VPP基于图的转发模型和矢量化数据包处理的TCP主机协议栈。

FD.io VPP每晚都会通过CSIT项目进行功能和性能测试。

有关这些功能的更多信息，请单击下面的链接或按下一步。

* [标量与矢量数据包处理](https://fd.io/docs/vpp/master/whatisvpp/scalar-vs-vector-packet-processing.html)
* [包处理图](https://fd.io/docs/vpp/master/whatisvpp/extensible.html)
* [网络协议栈](https://fd.io/docs/vpp/master/whatisvpp/networkstack.html)
* [TCP主机栈](https://fd.io/docs/vpp/master/whatisvpp/hoststack.html)
* [开发人员功能](https://fd.io/docs/vpp/master/whatisvpp/developer.html)
* [架构和操作系统](https://fd.io/docs/vpp/master/whatisvpp/supported.html)
* [性能](https://fd.io/docs/vpp/master/whatisvpp/performance.html)

<br/>


## 2.1. 标量与矢量数据包处理

FD.io VPP是`使用矢量包处理而非标量包`处理开发的。

**向量数据包处理是FD.io VPP和DPDK等高性能数据包处理应用程序中的常用方法**。基于标量的方法往往受到不一定具有严格性能要求的网络堆栈的青睐。

<br/>

### 2.1.1. 标量分组处理

标量数据包处理网络堆栈通常一次处理一个数据包：`中断处理功能从网络接口获取单个数据包`，并通过一组功能对其进行处理：fooA调用fooB调用fooC等等。

```
+---> fooA(packet1) +---> fooB(packet1) +---> fooC(packet1)
+---> fooA(packet2) +---> fooB(packet2) +---> fooC(packet2)
...
+---> fooA(packet3) +---> fooB(packet3) +---> fooC(packet3)
```
![](_v_images/20200907171041233_21708.png)

标量数据包处理很简单，但是在以下方面效率低下：

当代码路径长度超过微处理器指令高速缓存（I-cache）的大小时，由于微处理器不断地加载新指令而发生了抖动。在此模型中，每个数据包都会产生相同的`I缓存未命中集`。

当协议栈局部内存脱离微处理器的第1层数据缓存（D-cache）时，关联的深度调用堆栈还将增加负载存储单元压力。

<br/>

### 2.1.2. 矢量包处理

相反，矢量数据包处理网络堆栈一次处理多个数据包，称为“数据包矢量”或简称为“矢量”。中断处理函数从网络接口获取数据包的向量，并通过一组函数处理该向量：fooA调用fooB调用fooC等等。

```
+---> fooA([packet1, +---> fooB([packet1, +---> fooC([packet1, +--->
            packet2,             packet2,             packet2,
            ...                  ...                  ...
            packet256])          packet256])          packet256])
```
<br/>

![](_v_images/20200907171057871_5451.png)

此方法可修复：

* 通过分摊跨多个数据包的I-cache负载的成本，上述I-cache抖动问题。
* 通过从网络接口**一次接收多达256个数据包**的向量，并使用节点的有向图对其进行处理，从而与深度调用协议栈相关联的效率低下。**`图调度程序一次调用一个节点调度功能`，将堆栈深度限制为几个堆栈帧。**

这种方法实现的进一步优化是**流水线处理和预取**，以最大程度地减少表数据的读取延迟并并行化处理数据包所需的数据包负载。


<br/>

## 2.2. 包处理图

[包处理图](https://fd.io/docs/vpp/master/whatisvpp/extensible.html)

FD.io VPP设计的核心是`数据包处理图`。

这使得软件：

* 可插拔，易于理解和扩展
* 成熟的**图节点**架构
* 全面控制以重组管道
* 快速，插件是平等的公民

FD.io VPP数据包处理管道被分解为“数据包处理图”。这种模块化方法意味着任何人都可以“插入”新的图节点。这使得VPP易于扩展，并且意味着可以针对特定目的自定义插件。VPP也可以通过其低级API进行配置。

![图节点与插件](_v_images/20200907160042304_30427.png)

在运行时，FD.io VPP平台会`组合来自RX环的数据包向量`，通常单个向量中`最多256个数据包`。然后，`将包处理图逐个节点（包括插件）应用于整个包向量`。当将每个图节点表示的网络处理依次应用于每个包时，接收到的包通常会遍历向量中的包处理图节点。图节点是小型且模块化的，并且松散耦合。这使引入新图节点和重新连接现有图节点变得容易。

**`插件`是共享库 ，并在运行时由VPP加载。**VPP通过在插件路径中搜索库来查找插件，然后在启动时依次动态地加载每个插件。插件可以引入新的图节点或重新排列数据包处理图。您可以完全独立于FD.io VPP源代码树来构建插件，这意味着您可以将其视为独立的组件。


<br/>

## 2.3. 网络协议栈

本节简要介绍了FD.io网络堆栈，并介绍了一些优点：

* `第2-4层网络堆栈`
    快速查找表的路由，网桥条目
    任意n元组分类器
    控制平面，交通管理和覆盖

* `Linux和FreeBSD支持`
    支持标准操作系统接口，例如**`AF_Packet`，Tun / Tap和Netmap**。

* `DPDK的网络和加密硬件支持。`
* `容器和虚拟化支持`

    半虚拟化接口；虚拟主机和Virtio
    通过PCI直通的网络适配器
    本机容器接口；记忆体

* `主机栈`

* `通用数据平面：一个代码库，适用于许多用例`
    离散电器；如路由器和交换机。
    **云基础架构和虚拟网络功能**
    **云原生基础架构**
    所有用例都使用相同的二进制包。

* `借助CSIT开箱即用的生产质量。`

<br/>

## 2.4. TCP主机栈

VPP的主机堆栈利用VPP的基于图的转发模型和矢量化的数据包处理来确保高吞吐量和大规模传输协议的终止。它公开了各种API，这些API除了**允许有效使用用户空间的应用程序和生成数据**外，**还可以实现高效的本地应用程序间通信**。

在较高级别，VPP的主机栈包含3个主要组件：

* 促进传输协议和应用程序之间交互的`会话层`
* `可插拔的传输协议`，包括**TCP**，QUIC，TLS，**`UDP`****（协议组需要的UDP功能）**
* `VCL`（VPPComs库）是一组库，旨在从应用程序角度简化堆栈的易用性

所有这些组件都是定制构建的，以适合VPP的体系结构并利用其速度。

**在以下方面投入了大量精力：**

* 构建一个可传输的**可插入会话层**，该层使用定制的**共享内存**基础结构抽象应用程序和传输之间的交互。值得注意的是，这还允许将通常在应用程序中实现的传输协议（例如`QUIC`和`TLS`）在VPP中实现。
* **干净的TCP实现**，支持向量化数据包处理，并遵循VPP的高度可扩展的线程模型。该实现符合RFC，支持大量的高速TCP协议功能，并且已通过Defensic的Codenomicon 1M +测试套件进行了验证。
* **VCL**，一个`在用户空间中模拟传统异步通信功能的库`，同时允许在需要时开发新的模式。
* 实施高性能的**“直通”通信模式**，该模式使连接到vpp的应用程序可以`在共享内存上透明地交换数据`，而不会产生传统传输协议的额外费用。测试表明，此方法比传统的容器间网络高效得多。


![网络iso 7层](_v_images/20200904171130275_29912.png =480x)


<br/>

## 2.5. 开发人员功能

[开发人员功能](https://fd.io/docs/vpp/master/whatisvpp/developer.html)

本节介绍有关VPP环境以及开发人员可以使用的一些功能的一些信息。

* 广泛的运行时计数器；吞吐量，[每个周期的指令](https://en.wikipedia.org/wiki/Instructions_per_cycle)，错误，事件等。
* 综合管道追踪设施
* 多语言API绑定
* 集成命令行用于调试
* 容错和可升级
    作为容错的标准用户空间进程运行，软件崩溃很少需要重启进程。
    与在内核中运行类似的数据包处理相比，提高了容错性和可升级性，软件更新从不要求系统重启。
    与类似的内核代码相比，开发经验更容易
    硬件隔离和保护（[iommu](https://en.wikipedia.org/wiki/Input%E2%80%93output_memory_management_unit)）

* **为安全而打造**
    广泛的白盒测试
    图像段基地址随机化
    共享内存段基地址随机化
    堆栈边界检查
    具有Coverity的静态分析

<br/>

## 2.6. 架构和操作系统

<br/>

### 2.6.1. 支持的架构

<br/>

### 2.6.2. 操作系统

<br/>

## 2.7. 性能

FD.io VPP的优点之一是在相对低功耗的计算上具有高性能。包括以下内容。

* **专为商用硬件设计的高性能用户空间网络栈**：
    L2，L3和L4功能和封装。

* 优化的数据包接口，支持多种用例：
    集成的虚拟主机用户后端，可实现虚拟机到虚拟机的高速连接
    集成的memif容器后端，可实现高速的容器到容器连接
    一个基于vhost的集成接口，可将数据包发送到Linux内核

* 相同的优化代码路径在主机以及VM和Linux**容器**内部运行
* 利用同类最佳的开源驱动程序技术：[DPDK](https://www.dpdk.org/)
* 经过大规模测试；线性核心扩展，经过数百万个流和mac地址测试

设计这些功能是为了充分利用常见的微处理器优化技术，例如：

* 通过处理向量中的数据包减少缓存和TLS丢失
* 通过矢量指令（例如SSE，AVX和NEON）实现[IPC](https://en.wikipedia.org/wiki/Instructions_per_cycle)增益
* `消除模式切换，上下文切换和阻塞`，从而始终做有用的工作
* 缓存行`对齐`的缓冲区，提高缓存和内存效率

<br/>

### 2.7.1. 持续系统集成和测试（CSIT）
连续系统集成和测试（CSIT）项目为FD.io VPP提供功能和性能测试。此测试集中于功能和性能回归。结果将发布到CSIT测试报告中。

有关CSIT的更多信息，请查看以下链接：

* CSIT代码文档
* [CSIT测试概述](https://docs.fd.io/csit/master/report/introduction/overview.html)
* [VPP性能仪表板](https://docs.fd.io/csit/master/trending/introduction/index.html)

<br/>

### 2.7.2. CSIT数据包吞吐量示例

以下是一些CSIT测试报告的指针。测试的标题如下所示：

```
<数据包大小>-<线程数> <核心数>-<测试>-<接口类型>
```

例如，标题为`64b-2t1c-l2switching-base-i40e`的测试是`使用i40e接口使用64个字节的数据包，2个线程和1个核心进行l2交换`的测试。

这里有一些例子：

* [L2以太网交换](https://docs.fd.io/csit/master/report/vpp_performance_tests/packet_throughput_graphs/l2.html)
* [IPv4路由](https://docs.fd.io/csit/master/report/vpp_performance_tests/packet_throughput_graphs/ip4.html)
* IPv6路由

<br/>

### 2.7.3. 趋势吞吐量图

这些是CSIT 趋势仪表板中的一些趋势数据包吞吐量图。请注意，趋势图中的性能将根据软件开发周期每晚更改一次：

* 二层以太网交换趋势
* [IPv4路由趋势](https://docs.fd.io/csit/master/trending/trending/ip4.html)
* IPv6路由趋势






**`Should be MORE`**


<br/>

# 3. VPP入门

* [下载并安装VPP](https://fd.io/docs/vpp/master/gettingstarted/installing/index.html)
* [渐进式VPP教程](https://fd.io/docs/vpp/master/gettingstarted/progressivevpp/index.html)
* [对于用户](https://fd.io/docs/vpp/master/gettingstarted/users/index.html)
* [对于开发人员](https://fd.io/docs/vpp/master/gettingstarted/developers/index.html)
* [撰写文件](https://fd.io/docs/vpp/master/gettingstarted/writingdocs/index.html)

<br/>


## 3.1. 下载并安装VPP

如果要使用VPP，可以方便地从现有软件包中安装二进制文件。本指南介绍了如何提取，安装和运行VPP软件包。

本节提供有关如何在Ubuntu，Centos和openSUSE平台上安装VPP二进制文件的说明。

使用Package Cloud安装FD.io VPP。有关如何使用程序包云安装VPP的完整说明，请参阅程序包云。

**这里需要说明的是，因为我们公司内部不能连接互联网，起初我采用本节方案进行安装（添加yum源，yum install vpp*的方案），但后续由于dpdk的plugin加载不上，遂采用了源代码安装。**

<br/>

### 3.1.1. 在Ubuntu上安装

**`略`**

<br/>

### 3.1.2. 在Centos上安装

这部分会单独出一份文档，这里简单介绍官网的安装方法，这种方法没有配置DPDK插件。
[CentOS7安装VPP](https://fd.io/docs/vpp/master/gettingstarted/installing/centos.html)

<br/>

#### 3.1.2.1. 更新操作系统

在开始安装存储库之前，最好先更新和升级操作系统。运行以下命令以更新操作系统并获取一些软件包。

```bash
$ sudo yum update
$ sudo yum install pygpgme yum-utils
```

<br/>

#### 3.1.2.2. 软件包云存储库

构建工件也将发布到`packagecloud.io`存储库中。这包括官方的发行点。要使用这些构建工件中的任何一个，请创建一个文件 “ `/etc/yum.repos.d/fdio-release.repo`”，其内容指向所需的版本。以下是所需内容的一些常见示例：

<br/>

#### 3.1.2.3. VPP最新版本
要允许“ yum”访问官方VPP版本，请创建包含以下内容的文件 “ /etc/yum.repos.d/fdio-release.repo”。

```bash
$ cat /etc/yum.repos.d/fdio-release.repo
[fdio_release]
name=fdio_release
baseurl=https://packagecloud.io/fdio/release/el/7/$basearch
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/fdio/release/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300

[fdio_release-source]
name=fdio_release-source
baseurl=https://packagecloud.io/fdio/release/el/7/SRPMS
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/fdio/release/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300
```

更新您的本地yum缓存。

```bash
$ sudo yum clean all
$ sudo yum -q makecache -y --disablerepo='*' --enablerepo='fdio_release'
```

在“安装VPP”命令将安装最新的版本。要安装较早的发行版，请运行以下命令以获取所提供的发行版列表。

```bash
$ sudo yum --showduplicates list vpp* | expand
```

<br/>

#### 3.1.2.4. VPP Master分支
要允许yum从VPP master分支访问夜间版本，请创建具有以下内容的文件“ /etc/yum.repos.d/fdio-release.repo”。

```bash
$ cat /etc/yum.repos.d/fdio-release.repo
[fdio_master]
name=fdio_master
baseurl=https://packagecloud.io/fdio/master/el/7/$basearch
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/fdio/master/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300

[fdio_master-source]
name=fdio_master-source
baseurl=https://packagecloud.io/fdio/master/el/7/SRPMS
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/fdio/master/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300
```

更新您的本地yum缓存。

```bash
$ sudo yum clean all
$ sudo yum -q makecache -y --disablerepo='*' --enablerepo='fdio_master'
```


在“安装VPP”命令将在树枝上安装最新版本。运行以下命令以获取分支产生的图像列表。

```bash
$ sudo yum clean all
$ sudo yum --showduplicates list vpp* | expand
```

<br/>

#### 3.1.2.5. 安装VPP RPM

要安装VPP数据包引擎，请运行以下命令：

```bash
$ sudo yum install vpp
```

该VPP RPM依赖于VPP-LIB和VPP SELinux的政策 RPM的，所以它们将被安装好了。

*注意：该VPP SELinux的政策不会在系统上启用SELinux的。它将安装自定义VPP SELinux策略，如果随时启用SELinux，将使用该策略。*


还有其他可选软件包。这些软件包可以与上面的命令结合使用，一次安装，也可以根据需要安装：

```bash
sudo yum install vpp-plugins vpp-devel vpp-api-python vpp-api-lua vpp-api-java vpp-debuginfo vpp-devel libvpp0
```

<br/>

#### 3.1.2.6. 启动VPP

在系统上安装VPP后，要在CentOS上将VPP作为systemd服务运行，请运行以下命令：

```bash
$ sudo systemctl start vpp
```
然后，要使VPP在系统重新引导时启动，请运行以下命令：

```bash
$ sudo systemctl enable vpp
```
除了将VPP作为系统服务运行之外，还可以手动启动VPP或使其在GDB中运行以进行调试。有关更多详细信息和针对特定系统定制VPP的方法，请参阅运行VPP。

<br/>

#### 3.1.2.7. 卸载VPP RPM
要卸载VPP RPM，请运行以下命令：

```bash
$ sudo yum autoremove vpp*
```

<br/>

### 3.1.3. 在openSUSE上安装


**`略`**

<br/>

### 3.1.4. 安装包说明

**以下是与VPP一起安装的软件包的简要说明。**

* [**vpp**](https://fd.io/docs/vpp/master/gettingstarted/installing/packages.html#vpp)
    矢量包处理可执行文件。这是使用VPP必须安装的主要软件包。该软件包包含：
    vpp-矢量数据包引擎
    vpp_api_test-矢量数据包引擎API测试工具
    vpp_json_test-矢量数据包引擎JSON测试工具

* [**vpp-lib**](https://fd.io/docs/vpp/master/gettingstarted/installing/packages.html#vpp-lib)
    矢量包处理运行时库。该“VPP”的软件包依赖于这个包，所以它总是会被安装。该软件包包含VPP共享库，其中包括：
    vppinfra-支持矢量，哈希，位图，池和字符串格式的基础库。
    svm-虚拟机库
    vlib-矢量处理库
    vlib-api-二进制API库
    vnet-网络堆栈库

* [**vpp-plugins**](https://fd.io/docs/vpp/master/gettingstarted/installing/packages.html#vpp-plugins)
    矢量数据包处理插件模块。
    `acl`
    `dpdk`
    flowprobe
    gtpu
    ixge
    kubeproxy
    l2e
    lb
    memif
    nat
    pppoe
    sixrd
    stn

* [**vpp-dbg**](https://fd.io/docs/vpp/master/gettingstarted/installing/packages.html#vpp-dbg)
    矢量包处理调试符号。

* [**vpp-dev**](https://fd.io/docs/vpp/master/gettingstarted/installing/packages.html#vpp-dev)
    矢量包处理`开发支持`。该软件包包含VPP库的开发支持文件。

* **vpp-api-python**
    VPP Binary API的Python绑定。

* **vpp-api-lua**
    Lua绑定VPP Binary API。

* [**vpp-selinux-policy**](https://fd.io/docs/vpp/master/gettingstarted/installing/packages.html#vpp-selinux-policy)
    该软件包包含VPP定制SELinux策略。它仅为Fedora和CentOS发行版生成。对于那些发行版，“ vpp”软件包取决于此软件包，因此它将始终被安装。它不会在系统上启用SELinux。它将安装自定义VPP SELinux策略，如果随时启用SELinux，将使用该策略。


<br/>

## 3.2. 渐进式VPP教程

了解如何使用Vagrant在单个Ubuntu 16.04 VM上运行FD.io VPP，本演练涵盖了基本FD.io VPP方案。将使用有用的FD.io VPP命令，并将讨论基本操作以及系统上正在运行的FD.io VPP的状态。

*注意：这并非旨在作为“如何在生产环境中运行”的一组说明。*


<br/>

### 3.2.1. 设置环境

***PS：Vagrant是一个基于Ruby的工具，用于创建和部署虚拟化开发环境.***

有关将`VPP与Virtual Box / Vagrant一​​起使用`的更多信息，请参阅[VM与Vagrant一​​起使用](https://fd.io/docs/vpp/master/reference/vppvagrant/index.html#vppvagrant)

<br/>

#### 3.2.1.1. 安装Virtual Box和Vagrant

**`略`**

<br/>

#### 3.2.1.2. 创建一个Vagrant目录

**`略`**

<br/>

#### 3.2.1.3. 运行Vagrant

**`略`**

<br/>

#### 3.2.1.4. 使用Vagrant设置VPP环境

**`略`**

<br/>

#### 3.2.1.5. 安装VPP

这部分会单独出一份文档，这里简单介绍官网的安装方法，这种方法没有配置DPDK插件。
[CentOS7安装VPP](https://fd.io/docs/vpp/master/gettingstarted/installing/centos.html)
**`略`**

#### 3.2.1.6. 创建一些启动文件

我们将创建一些启动文件供本教程使用。通常，您将修改`/etc/vpp/startup.conf`中的startup.conf文件。有关此文件的更多信息，请参考`VPP配置-CLI`和`'startup.conf'`。

在运行多个VPP实例时，每个实例都需要指定一个“名称”或“前缀”。在下面的示例中，“名称”或“前缀”为“ vpp1”。请注意，只有一个实例可以使用dpdk插件，因为该插件正在尝试获取文件的锁。我们创建的这些启动文件将禁用dpdk插件。

还要在我们的启动文件中注意`api-segment`。`api-segment {prefix vpp1}` 告诉FD.io VPP如何用不同于默认名称的方式为您的VPP实例命名`/ dev / shm /`中的文件。`unix {cli-listen /run/vpp/cli-vpp1.sock}` 告诉vpp在被`vppctl`寻址时使用非默认套接字文件。这里我也会单独做出配置文件`/etc/vpp/startup.conf`的详细说明（荣涛 [rongtao@sylincom.com](rongtao@sylincom.com)）。

现在，使用以下内容创建2个名为**startup1.conf**和**startup2.conf**的文件。这些文件可以位于任何地方。启动VPP时，我们指定位置。

**startup1.conf：**
```
unix {cli-listen /run/vpp/cli-vpp1.sock}
api-segment { prefix vpp1 }
plugins { plugin dpdk_plugin.so { disable } }
```

**startup2.conf：**

```
unix {cli-listen /run/vpp/cli-vpp2.sock}
api-segment { prefix vpp2 }
plugins { plugin dpdk_plugin.so { disable } }
```

<br/>

### 3.2.2. 运行VPP

使用我们在设置环境中创建的文件，我们现在将启动并运行VPP。

VPP在用户空间中运行。在生产环境中，通常会使用DPDK来运行它以连接到实际的NIC或使用vhost来连接到VM。在这种情况下，通常会运行一个VPP实例。

就本教程而言，运行多个VPP实例并将它们彼此连接以形成拓扑将非常有用。幸运的是，VPP支持这一点。

使用我们在安装程序中创建的文件，我们将启动VPP。

```
$ sudo /usr/bin/vpp -c startup1.conf
vlib_plugin_early_init:361: plugin path /usr/lib/vpp_plugins:/usr/lib/vpp_plugins
load_one_plugin:189: Loaded plugin: abf_plugin.so (ACL based Forwarding)
load_one_plugin:189: Loaded plugin: acl_plugin.so (Access Control Lists)
load_one_plugin:189: Loaded plugin: avf_plugin.so (Intel Adaptive Virtual Function (AVF) Device Plugin)
.........
$
```

**如果VPP无法启动**，则可以尝试将`nodaemon`添加到unix部分的`startup.conf`文件中 。

使用nodaemon的startup.conf示例：

```
unix {nodaemon cli-listen /run/vpp/cli-vpp1.sock}
api-segment { prefix vpp1 }
plugins { plugin dpdk_plugin.so { disable } }
```

命令`vppctl`将启动一个`VPP Shell`，您可以使用它以交互方式运行VPP命令。

现在，我们应该能够执行VPP Shell并显示版本了。

```
$ sudo vppctl -s /run/vpp/cli-vpp1.sock
    _______    _        _   _____  ___
 __/ __/ _ \  (_)__    | | / / _ \/ _ \
 _/ _// // / / / _ \   | |/ / ___/ ___/
 /_/ /____(_)_/\___/   |___/_/  /_/

vpp# show version
vpp v18.07-release built by root on c469eba2a593 at Mon Jul 30 23:27:03 UTC 2018
vpp#
```

![VPP的命令行截图](_v_images/20200904180458392_20546.png)

*注意：使用ctrl-d或q退出VPP Shell。*

**如果要运行多个VPP实例，请确保在完成后将其杀死**。

您可以使用如下所示的内容：

```bash
$ ps -eaf | grep vpp
root      2067     1  2 05:12 ?        00:00:00 /usr/bin/vpp -c startup1.conf
vagrant   2070   903  0 05:12 pts/0    00:00:00 grep --color=auto vpp
$ kill -9 2067
$ ps -eaf | grep vpp
vagrant   2074   903  0 05:13 pts/0    00:00:00 grep --color=auto vpp
```


<br/>

### 3.2.3. 创建一个接口

[创建一个接口](https://fd.io/docs/vpp/master/gettingstarted/progressivevpp/interface.html)

<br/>

#### 3.2.3.1. 要学习的技能

* 在Linux主机中创建veth接口
* 在Linux主机中的第veth个接口的一端分配IP地址
* 创建一个通过AF_PACKET连接到veth接口一端的vpp主机接口
* 将IP地址添加到vpp接口

<br/>

#### 3.2.3.2. 在本练习中学习的VPP命令

* 创建主机接口
* 设置int状态
* 设置内部IP地址
* 显示硬件
* 显示诠释
* 显示int地址
* 跟踪添加
* 清除痕迹
* ping
* 显示ip arp
* 显示IP FIB

<br/>

#### 3.2.3.3. 拓扑结构

<br/>

**注意：我们的环境是DPDK+VPP，在物理机中部署，使用真实Intel 10G网卡，所以我们不需要做本章节中由物理网卡虚拟出虚拟网卡的步骤。**

<br/>

网卡型号如下：

```bash
lspci | grep 10G
3b:00.0 Ethernet controller: Intel Corporation Ethernet 10G 2P X520 Adapter (rev 01)
3b:00.1 Ethernet controller: Intel Corporation Ethernet 10G 2P X520 Adapter (rev 01)
```

![图：创建接口拓扑](_v_images/20200907091916498_6937.jpg)

<br/>

#### 3.2.3.4. 初始状态
在本教程的前面各节中，假定此处的初始状态为最终状态。

<br/>

#### 3.2.3.5. 在主机上创建veth接口
在Linux中，有一种类型的接口称为“ veth”。将“ veth”接口视为具有两端（而不是一端）的接口。

创建一个veth接口，一端名为vpp1out，另一端名为vpp1host

```bash
$ sudo ip link add name vpp1out type veth peer name vpp1host
```

**UP网口：**

```bash
$ sudo ip link set dev vpp1out up
$ sudo ip link set dev vpp1host up
```

**分配IP地址**

```bash
$ sudo ip addr add 10.10.1.1/24 dev vpp1host
```

显示结果：

```bash
$ ip addr show vpp1host
5: vpp1host@vpp1out: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
  link/ether e2:0f:1e:59:ec:f7 brd ff:ff:ff:ff:ff:ff
  inet 10.10.1.1/24 scope global vpp1host
     valid_lft forever preferred_lft forever
  inet6 fe80::e00f:1eff:fe59:ecf7/64 scope link
     valid_lft forever preferred_lft forever
```

<br/>

#### 3.2.3.6. 创建vpp主机接口

确保VPP正在运行（如果未启动）。

```
$ ps -eaf | grep vpp
vagrant   2141   903  0 05:28 pts/0    00:00:00 grep --color=auto vpp
# 4. vpp is not running, so start it
$ sudo /usr/bin/vpp -c startup1.conf
```

这些命令从vpp shell运行。使用以下命令输入VPP Shell：

```
$ sudo vppctl -s /run/vpp/cli-vpp1.sock
    _______    _        _   _____  ___
 __/ __/ _ \  (_)__    | | / / _ \/ _ \
 _/ _// // / / / _ \   | |/ / ___/ ___/
 /_/ /____(_)_/\___/   |___/_/  /_/

vpp#
```

创建附加到vpp1out的主机接口。

```
vpp# create host-interface name vpp1out
host-vpp1out
```

确认接口：

```
vpp# show hardware
              Name                Idx   Link  Hardware
host-vpp1out                       1     up   host-vpp1out
Ethernet address 02:fe:d9:75:d5:b4
Linux PACKET socket interface
local0                             0    down  local0
local
```

打开接口：

```
vpp# set int state host-vpp1out up
```

确认接口已启动：

```
vpp# show int
              Name               Idx    State  MTU (L3/IP4/IP6/MPLS)     Counter          Count
host-vpp1out                      1      up          9000/0/0/0
local0                            0     down          0/0/0/0
```

分配IP地址10.10.1.2/24

```
vpp# set int ip address host-vpp1out 10.10.1.2/24
```

确认已分配IP地址：

```
vpp# show int addr
host-vpp1out (up):
  L3 10.10.1.2/24
local0 (dn):
```

<br/>

### 3.2.4. 使用trace命令

#### 3.2.4.1. 要学习的技能

* 设置“trace”
* 查看“trace”
* 清除“trace”
* 使用主机上的ping进行验证
* 从vpp ping
* 检查ARP表
* 检查ip fib

<br/>

#### 3.2.4.2. 基本跟踪命令

显示跟踪缓冲区[最大COUNT]。~~*下面的trace命令，我在执行过程中，好像没有什么返回。*~~

```
vpp# show trace
```

清除跟踪缓冲区和可用内存。

```
vpp# clear trace
```

过滤器跟踪输出-包含NODE COUNT | 排除NODE COUNT | 没有。

```
vpp# trace filter <include NODE COUNT | exclude NODE COUNT | none>
```

<br/>

#### 3.2.4.3. 添加跟踪

```
vpp# trace add af-packet-input 10
```

**跟踪添加支持以下节点列表：**

* AF数据包输入
* avf输入
* 键合过程
* dpdk-crypto-input
* dpdk输入
* 切换轨迹
* ixge输入
* 记忆输入
* mrvl-pp2-输入
* 网图输入
* p2p-以太网输入
* pg输入
* Punt-socket-rx
* rdma输入
* 会话队列
* tuntap-rx
* 虚拟主机用户输入
* 虚拟输入
* vmxnet3-输入

<br/>

#### 3.2.4.4. 从主机到VPP ping

```
vpp# q
$ ping -c 1 10.10.1.2
PING 10.10.1.2 (10.10.1.2) 56(84) bytes of data.
64 bytes from 10.10.1.2: icmp_seq=1 ttl=64 time=0.283 ms

--- 10.10.1.2 ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 0ms
rtt min/avg/max/mdev = 0.283/0.283/0.283/0.000 ms
```

<br/>

#### 3.2.4.5. 检查从主机到VPP的ping跟踪

```
$ sudo vppctl -s /run/vpp/cli-vpp1.sock
vpp# show trace
------------------- Start of thread 0 vpp_main -------------------
Packet 1

00:17:04:099260: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e370 nsec 0x3af2736f vlan 0 vlan_tpid 0
00:17:04:099269: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:17:04:099285: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099290: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099296: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3f7c
    fragment id 0xe516, flags DONT_FRAGMENT
  ICMP echo_request checksum 0xc043
00:17:04:099300: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099301: ip4-icmp-echo-request
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099303: ip4-load-balance
fib 0 dpo-idx 13 flow hash: 0x00000000
ICMP: 10.10.1.2 -> 10.10.1.1
  tos 0x00, ttl 64, length 84, checksum 0x4437
  fragment id 0xe05b, flags DONT_FRAGMENT
ICMP echo_reply checksum 0xc843
00:17:04:099305: ip4-rewrite
tx_sw_if_index 1 dpo-idx 1 : ipv4 via 10.10.1.1 host-vpp1out: mtu:9000 e20f1e59ecf702fed975d5b40800 flow hash: 0x00000000
00000000: e20f1e59ecf702fed975d5b4080045000054e05b4000400144370a0a01020a0a
00000020: 01010000c8437c92000170e3605b000000001c170f00000000001011
00:17:04:099307: host-vpp1out-output
host-vpp1out
IP4: 02:fe:d9:75:d5:b4 -> e2:0f:1e:59:ec:f7
ICMP: 10.10.1.2 -> 10.10.1.1
  tos 0x00, ttl 64, length 84, checksum 0x4437
  fragment id 0xe05b, flags DONT_FRAGMENT
ICMP echo_reply checksum 0xc843
```

<br/>

#### 3.2.4.6. 清除跟踪缓冲区

```
vpp# clear trace
```

<br/>

#### 3.2.4.7. 从VPP ping主机

**这一步，我们可以完成。-荣涛**

```
vpp# ping 10.10.1.1
64 bytes from 10.10.1.1: icmp_seq=1 ttl=64 time=.0789 ms
64 bytes from 10.10.1.1: icmp_seq=2 ttl=64 time=.0619 ms
64 bytes from 10.10.1.1: icmp_seq=3 ttl=64 time=.0519 ms
64 bytes from 10.10.1.1: icmp_seq=4 ttl=64 time=.0514 ms
64 bytes from 10.10.1.1: icmp_seq=5 ttl=64 time=.0526 ms

Statistics: 5 sent, 5 received, 0% packet loss
```

<br/>

#### 3.2.4.8. 检查从VPP到主机的ping跟踪

输出将演示FD.io VPP对所有数据包执行ping操作的跟踪。

```
vpp# show trace
------------------- Start of thread 0 vpp_main -------------------
Packet 1

00:17:04:099260: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e370 nsec 0x3af2736f vlan 0 vlan_tpid 0
00:17:04:099269: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:17:04:099285: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099290: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099296: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3f7c
    fragment id 0xe516, flags DONT_FRAGMENT
  ICMP echo_request checksum 0xc043
00:17:04:099300: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099301: ip4-icmp-echo-request
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f7c
  fragment id 0xe516, flags DONT_FRAGMENT
ICMP echo_request checksum 0xc043
00:17:04:099303: ip4-load-balance
fib 0 dpo-idx 13 flow hash: 0x00000000
ICMP: 10.10.1.2 -> 10.10.1.1
  tos 0x00, ttl 64, length 84, checksum 0x4437
  fragment id 0xe05b, flags DONT_FRAGMENT
ICMP echo_reply checksum 0xc843
00:17:04:099305: ip4-rewrite
tx_sw_if_index 1 dpo-idx 1 : ipv4 via 10.10.1.1 host-vpp1out: mtu:9000 e20f1e59ecf702fed975d5b40800 flow hash: 0x00000000
00000000: e20f1e59ecf702fed975d5b4080045000054e05b4000400144370a0a01020a0a
00000020: 01010000c8437c92000170e3605b000000001c170f00000000001011
00:17:04:099307: host-vpp1out-output
host-vpp1out
IP4: 02:fe:d9:75:d5:b4 -> e2:0f:1e:59:ec:f7
ICMP: 10.10.1.2 -> 10.10.1.1
  tos 0x00, ttl 64, length 84, checksum 0x4437
  fragment id 0xe05b, flags DONT_FRAGMENT
ICMP echo_reply checksum 0xc843

Packet 2

00:17:09:113964: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 42 snaplen 42 mac 66 net 80
    sec 0x5b60e375 nsec 0x3b3bd57d vlan 0 vlan_tpid 0
00:17:09:113974: ethernet-input
ARP: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:17:09:113986: arp-input
request, type ethernet/IP4, address size 6/4
e2:0f:1e:59:ec:f7/10.10.1.1 -> 00:00:00:00:00:00/10.10.1.2
00:17:09:114003: host-vpp1out-output
host-vpp1out
ARP: 02:fe:d9:75:d5:b4 -> e2:0f:1e:59:ec:f7
reply, type ethernet/IP4, address size 6/4
02:fe:d9:75:d5:b4/10.10.1.2 -> e2:0f:1e:59:ec:f7/10.10.1.1

Packet 3

00:18:16:407079: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e3b9 nsec 0x90b7566 vlan 0 vlan_tpid 0
00:18:16:407085: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:18:16:407090: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3fe8
  fragment id 0x24ab
ICMP echo_reply checksum 0x37eb
00:18:16:407094: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3fe8
  fragment id 0x24ab
ICMP echo_reply checksum 0x37eb
00:18:16:407097: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3fe8
    fragment id 0x24ab
  ICMP echo_reply checksum 0x37eb
00:18:16:407101: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3fe8
  fragment id 0x24ab
ICMP echo_reply checksum 0x37eb
00:18:16:407104: ip4-icmp-echo-reply
ICMP echo id 7531 seq 1
00:18:16:407108: ip4-drop
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3fe8
    fragment id 0x24ab
  ICMP echo_reply checksum 0x37eb
00:18:16:407111: error-drop
ip4-icmp-input: unknown type

Packet 4

00:18:17:409084: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e3ba nsec 0x90b539f vlan 0 vlan_tpid 0
00:18:17:409088: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:18:17:409092: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f40
  fragment id 0x2553
ICMP echo_reply checksum 0xcc6d
00:18:17:409095: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f40
  fragment id 0x2553
ICMP echo_reply checksum 0xcc6d
00:18:17:409097: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3f40
    fragment id 0x2553
  ICMP echo_reply checksum 0xcc6d
00:18:17:409099: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3f40
  fragment id 0x2553
ICMP echo_reply checksum 0xcc6d
00:18:17:409101: ip4-icmp-echo-reply
ICMP echo id 7531 seq 2
00:18:17:409104: ip4-drop
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3f40
    fragment id 0x2553
  ICMP echo_reply checksum 0xcc6d
00:18:17:409104: error-drop
ip4-icmp-input: unknown type

Packet 5

00:18:18:409082: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e3bb nsec 0x8ecad24 vlan 0 vlan_tpid 0
00:18:18:409087: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:18:18:409091: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e66
  fragment id 0x262d
ICMP echo_reply checksum 0x8e59
00:18:18:409093: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e66
  fragment id 0x262d
ICMP echo_reply checksum 0x8e59
00:18:18:409096: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3e66
    fragment id 0x262d
  ICMP echo_reply checksum 0x8e59
00:18:18:409098: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e66
  fragment id 0x262d
ICMP echo_reply checksum 0x8e59
00:18:18:409099: ip4-icmp-echo-reply
ICMP echo id 7531 seq 3
00:18:18:409102: ip4-drop
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3e66
    fragment id 0x262d
  ICMP echo_reply checksum 0x8e59
00:18:18:409102: error-drop
ip4-icmp-input: unknown type

Packet 6

00:18:19:414750: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e3bc nsec 0x92450f2 vlan 0 vlan_tpid 0
00:18:19:414754: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:18:19:414757: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e52
  fragment id 0x2641
ICMP echo_reply checksum 0x9888
00:18:19:414760: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e52
  fragment id 0x2641
ICMP echo_reply checksum 0x9888
00:18:19:414762: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3e52
    fragment id 0x2641
  ICMP echo_reply checksum 0x9888
00:18:19:414764: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e52
  fragment id 0x2641
ICMP echo_reply checksum 0x9888
00:18:19:414765: ip4-icmp-echo-reply
ICMP echo id 7531 seq 4
00:18:19:414768: ip4-drop
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3e52
    fragment id 0x2641
  ICMP echo_reply checksum 0x9888
00:18:19:414769: error-drop
ip4-icmp-input: unknown type

Packet 7

00:18:20:418038: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 98 snaplen 98 mac 66 net 80
    sec 0x5b60e3bd nsec 0x937bcc2 vlan 0 vlan_tpid 0
00:18:20:418042: ethernet-input
IP4: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:18:20:418045: ip4-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e47
  fragment id 0x264c
ICMP echo_reply checksum 0xc0e8
00:18:20:418048: ip4-lookup
fib 0 dpo-idx 5 flow hash: 0x00000000
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e47
  fragment id 0x264c
ICMP echo_reply checksum 0xc0e8
00:18:20:418049: ip4-local
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3e47
    fragment id 0x264c
  ICMP echo_reply checksum 0xc0e8
00:18:20:418054: ip4-icmp-input
ICMP: 10.10.1.1 -> 10.10.1.2
  tos 0x00, ttl 64, length 84, checksum 0x3e47
  fragment id 0x264c
ICMP echo_reply checksum 0xc0e8
00:18:20:418054: ip4-icmp-echo-reply
ICMP echo id 7531 seq 5
00:18:20:418057: ip4-drop
  ICMP: 10.10.1.1 -> 10.10.1.2
    tos 0x00, ttl 64, length 84, checksum 0x3e47
    fragment id 0x264c
  ICMP echo_reply checksum 0xc0e8
00:18:20:418058: error-drop
ip4-icmp-input: unknown type

Packet 8

00:18:21:419208: af-packet-input
af_packet: hw_if_index 1 next-index 4
  tpacket2_hdr:
    status 0x20000001 len 42 snaplen 42 mac 66 net 80
    sec 0x5b60e3be nsec 0x92a9429 vlan 0 vlan_tpid 0
00:18:21:419876: ethernet-input
ARP: e2:0f:1e:59:ec:f7 -> 02:fe:d9:75:d5:b4
00:18:21:419881: arp-input
request, type ethernet/IP4, address size 6/4
e2:0f:1e:59:ec:f7/10.10.1.1 -> 00:00:00:00:00:00/10.10.1.2
00:18:21:419896: host-vpp1out-output
host-vpp1out
ARP: 02:fe:d9:75:d5:b4 -> e2:0f:1e:59:ec:f7
reply, type ethernet/IP4, address size 6/4
02:fe:d9:75:d5:b4/10.10.1.2 -> e2:0f:1e:59:ec:f7/10.10.1.1
```

检查跟踪之后，请使用`vpp＃clear trace`再次将其清除。

<br/>

#### 3.2.4.9. 检查ARP表

**这个我运行也查不到啊。-荣涛**

```
vpp# show ip arp
Time           IP4       Flags      Ethernet              Interface
1101.5636    10.10.1.1      D    e2:0f:1e:59:ec:f7 host-vpp1out
```

没有这个命令，难道说arp这个也是个插件，我没有加再进来？

```
RToax-VPP# show ip help
  container                      show ip container <address> <interface>
  fib                            show ip fib [summary] [table <table-id>] [index <fib-id>] [<ip4-addr>[/<mask>]] [m
trie] [detail]  local                          show ip local
  mfib                           show ip mfib [summary] [table <table-id>] [index <fib-id>] [<grp-addr>[/<mask>]] [
<grp-addr>] [<src-addr> <grp-addr>]  neighbors                      show ip neighbors [interface]
  neighbor                       show ip neighbor [interface]
  neighbor-config                show ip neighbor-config
  neighbor-watcher               show ip neighbors-watcher
  punt                           show ip punt commands
  source-and-port-range-check    show ip source-and-port-range-check vrf <table-id> <ip-addr> [port <n>]
```

<br/>


#### 3.2.4.10. 检查路由表

```
RToax-VPP# show ip fib  
ipv4-VRF:0, fib_index:0, flow hash:[src dst sport dport proto ] epoch:0 flags:none locks:[adjacency:1, recursive-re
solution:1, default-route:1, nat-hi:2, ]0.0.0.0/0
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:1 buckets:1 uRPF:0 to:[7523169:7733662576]]
    [0] [@0]: dpo-drop ip4
0.0.0.0/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:2 buckets:1 uRPF:1 to:[0:0]]
    [0] [@0]: dpo-drop ip4
10.170.6.0/24
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:14 buckets:1 uRPF:16 to:[650:330002]]
    [0] [@12]: dpo-load-balance: [proto:ip4 index:13 buckets:1 uRPF:10 to:[0:0] via:[650:330002]]
          [0] [@5]: ipv4 via 10.170.7.254 dpdk0: mtu:9000 next:3 346b5bf046c1b496916db4cc0800
10.170.7.0/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:10 buckets:1 uRPF:11 to:[0:0]]
    [0] [@0]: dpo-drop ip4
10.170.7.2/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:38 buckets:1 uRPF:42 to:[67:3410]]
    [0] [@5]: ipv4 via 10.170.7.2 dpdk0: mtu:9000 next:3 b82a72d0067eb496916db4cc0800
10.170.7.3/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:24 buckets:1 uRPF:28 to:[368:63324]]
    [0] [@5]: ipv4 via 10.170.7.3 dpdk0: mtu:9000 next:3 eca86b30f687b496916db4cc0800
10.170.7.7/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:46 buckets:1 uRPF:50 to:[6:426]]
    [0] [@5]: ipv4 via 10.170.7.7 dpdk0: mtu:9000 next:3 0023247dc5eab496916db4cc0800
10.170.7.30/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:32 buckets:1 uRPF:36 to:[518:291334]]
    [0] [@5]: ipv4 via 10.170.7.30 dpdk0: mtu:9000 next:3 b82a72d03edab496916db4cc0800
10.170.7.32/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:44 buckets:1 uRPF:48 to:[1:104]]
    [0] [@5]: ipv4 via 10.170.7.32 dpdk0: mtu:9000 next:3 000c29ed4141b496916db4cc0800
10.170.7.35/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:21 buckets:1 uRPF:25 to:[505:41886]]
    [0] [@5]: ipv4 via 10.170.7.35 dpdk0: mtu:9000 next:3 a4bf01041deab496916db4cc0800
10.170.7.65/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:23 buckets:1 uRPF:27 to:[641:38620]]
    [0] [@5]: ipv4 via 10.170.7.65 dpdk0: mtu:9000 next:3 e4434b3088d4b496916db4cc0800
10.170.7.79/32
  unicast-ip4-chain
  [@0]: dpo-load-balance: [proto:ip4 index:39 buckets:1 uRPF:43 to:[42:4566]]
    [0] [@5]: ipv4 via 10.170.7.79 dpdk0: mtu:9000 next:3 000c2907ec7cb496916db4cc0800

```

<br/>

### 3.2.5. 连接两个FD.io VPP实例

[连接两个FD.io VPP实例](https://fd.io/docs/vpp/master/gettingstarted/progressivevpp/twovppinstances.html)

`memif`是一种非常高性能的直接内存接口类型，可以在FD.io VPP实例之间使用。它使用文件套接字作为控制通道来设置**共享内存**。

这里，我把他理解成，VPP支持的两个进程间通信，采用memif进行通信，memif的实现机制是共享内存。

<br/>

#### 3.2.5.1. 要学习的技能

您将在此练习中学习以下新技能：

* 在两个FD.io VPP实例之间创建一个`memif接口`

您应该能够使用先前练习中学到的以下技能来执行此练习：

* 运行第二个FD.io VPP实例
* 将IP地址添加到FD.io VPP接口
* 来自FD.io VPP的Ping

<br/>

#### 3.2.5.2. 拓扑结构

![连接两个FD.io VPP拓扑](_v_images/20200907102204795_1499.png)

<br/>

#### 3.2.5.3. 初始状态

假定此处的初始状态是练习中的最终状态。

<br/>

#### 3.2.5.4. 运行第二个FD.io VPP实例

您应该已经有一个运行的FD.io VPP实例，名为：vpp1。

运行另一个名为vpp2的FD.io VPP实例。

```
$ sudo /usr/bin/vpp -c startup2.conf
....
$ sudo vppctl -s /run/vpp/cli-vpp2.sock
    _______    _        _   _____  ___
 __/ __/ _ \  (_)__    | | / / _ \/ _ \
 _/ _// // / / / _ \   | |/ / ___/ ___/
 /_/ /____(_)_/\___/   |___/_/  /_/

vpp# show version
vpp v18.07-release built by root on c469eba2a593 at Mon Jul 30 23:27:03 UTC 2018
vpp# quit
```

<br/>

#### 3.2.5.5. 在vpp1上创建memif接口
在vpp1上创建一个memif接口。要连接到实例vpp1，请使用套接字/run/vpp/cli-vpp1.sock

```
$ sudo vppctl -s /run/vpp/cli-vpp1.sock
vpp# create interface memif id 0 master
```

这将使用`/ run / vpp / memif`作为其套接字文件在`vpp1 memif0 / 0`上创建一个接口。此memif接口的vpp1角色是“主”。

通过所学的知识：

* 将memif0 / 0状态设置为up。
* 将IP地址10.10.2.1/24分配给memif0 / 0
* 通过show命令检查memif0 / 0

<br/>

#### 3.2.5.6. 在vpp2上创建memif接口
我们希望vpp2使用相同的run / vpp / memif-vpp1vpp2套接字文件来承担“从属”角色

```
vpp# create interface memif id 0 slave
```

这将使用/ run / vpp / memif作为其套接字文件在vpp2 memif0 / 0上创建一个接口。此memif接口的vpp1角色是“从属”。

使用您以前使用的技能来：

* 将memif0 / 0状态设置为up。
* 将IP地址10.10.2.2/24分配给memif0 / 0
* 通过show命令检查memif0 / 0

<br/>

#### 3.2.5.7. 从vpp1 ping到vpp2

从vpp1 Ping 10.10.2.2

```
$ ping 10.10.2.2
```

从vpp2 Ping 10.10.2.1

```
$ ping 10.10.2.1
```

<br/>

### 3.2.6. 路由

<br/>

#### 3.2.6.1. 要学习的技能
在本练习中，您将学习以下新技能：

* 将路由添加到Linux主机路由表
* 将路由添加到FD.io VPP路由表

并重温旧的：

* 检查FD.io VPP路由表
* 在vpp1和vpp2上启用跟踪
* 从主机ping到FD.io VPP
* 检查并清除vpp1和vpp2上的跟踪
* 从FD.io VPP ping到主机
* 检查并清除vpp1和vpp2上的跟踪

<br/>

#### 3.2.6.2. 在本练习中学习了VPP命令
[ip路由添加](https://docs.fd.io/vpp/17.04/clicmd_src_vnet_ip.html#clicmd_ip_route)

<br/>

#### 3.2.6.3. 拓扑结构

连接两个FD.io VPP拓扑
![拓扑结构](_v_images/20200907105915271_9141.png)

#### 3.2.6.4. 初始状态
假定此初始状态是[连接两个FD.io VPP实例](https://fd.io/docs/vpp/master/gettingstarted/progressivevpp/VPP/Progressive_VPP_Tutorial#Connecting_two_vpp_instances)的练习的最终状态

#### 3.2.6.5. 设置主机路由
```
$ sudo ip route add 10.10.2.0/24 via 10.10.1.2
$ ip route
default via 10.0.2.2 dev enp0s3
10.0.2.0/24 dev enp0s3  proto kernel  scope link  src 10.0.2.15
10.10.1.0/24 dev vpp1host  proto kernel  scope link  src 10.10.1.1
10.10.2.0/24 via 10.10.1.2 dev vpp1host
```

#### 3.2.6.6. 在vpp2上设置返回路线
```
$ sudo vppctl -s /run/vpp/cli-vpp2.sock
 vpp# ip route add 10.10.1.0/24  via 10.10.2.1
```
#### 3.2.6.7. 从主机通过vpp1 ping至vpp2
从vpp1到vpp2的连接使用memif驱动程序，到主机的连接使用af-packet驱动程序。要跟踪来自主机的数据包，我们使用从vpp1到vpp2的af-packet-input，我们使用memif-input。

* 在vpp1和vpp2上设置跟踪
* 从主机Ping 10.10.2.2
* 检查vpp1和vpp2上的跟踪
* 清除vpp1和vpp2上的跟踪


### 3.2.7. 交换
#### 3.2.7.1. 要学习的技能

* 将接口与网桥域相关联
* 创建回送接口
* 为网桥域创建BVI（网桥虚拟接口）
* 检查桥域

#### 3.2.7.2. 在本练习中学习了FD.io VPP命令

* [桥接](https://docs.fd.io/vpp/17.04/clicmd_src_vnet_l2.html#clicmd_show_bridge-domain)
* [显示桥接细节](https://docs.fd.io/vpp/17.04/clicmd_src_vnet_l2.html#clicmd_show_bridge-domain)
* [设置int l2桥](https://docs.fd.io/vpp/17.04/clicmd_src_vnet_l2.html#clicmd_set_interface_l2_bridge)
* [显示详细的l2fib](https://docs.fd.io/vpp/17.04/clicmd_src_vnet_l2.html#clicmd_show_l2fib)

#### 3.2.7.3. 拓扑结构

![拓扑结构](_v_images/20200907110359654_1018.jpg)

#### 3.2.7.4. 初始状态

与以前的练习不同，对于此练习，您要开始进行表格绘制。

注意：您将丢失FD.io VPP实例中的所有现有配置！

要从以前的练习中清除现有配置，请运行：
```
$ ps -ef | grep vpp | awk '{print $2}'| xargs sudo kill
$ sudo ip link del dev vpp1host
$ # do the next command if you are cleaning up from this example
$ sudo ip link del dev vpp1vpp2
```

#### 3.2.7.5. 运行FD.io VPP实例

1.运行名为vpp1的vpp实例
2.运行名为vpp2的vpp实例

#### 3.2.7.6. 将vpp1连接到主机

* 创建一个veth，一端名为vpp1host，另一端名为vpp1out。
* 将vpp1out连接到vpp1
* 在vpp1host上添加IP地址10.10.1.1/24

#### 3.2.7.7. 将vpp1连接到vpp2

* 创建一端名为vpp1vpp2且另一端名为vpp2vpp1的veth。
* 将vpp1vpp2连接到vpp1。
* 将vpp2vpp1连接到vpp2。

#### 3.2.7.8. 在vpp1上配置网桥域
检查以查看已经存在哪些桥接域，然后选择第一个未使用的桥接域号：

```
vpp# show bridge-domain
 ID   Index   Learning   U-Forwrd   UU-Flood   Flooding   ARP-Term     BVI-Intf
 0      0        off        off        off        off        off        local0
```
在上面的示例中，网桥域ID已经为“ 0”。即使有时我们可能会收到如下反馈：
```
no bridge-domains in use
```
网桥域ID“ 0”仍然存在，不支持任何操作。例如，如果我们尝试将host-vpp1out和host-vpp1vpp2添加到网桥域ID 0，则将无法进行任何设置。
```
vpp# set int l2 bridge host-vpp1out 0
vpp# set int l2 bridge host-vpp1vpp2 0
vpp# show bridge-domain 0 detail
show bridge-domain: No operations on the default bridge domain are supported
```
因此，我们将创建桥域1而不是使用默认桥域ID 0进行播放。

将host-vpp1out添加到网桥域ID 1
```
vpp# set int l2 bridge host-vpp1out 1
```
将host-vpp1vpp2添加到网桥域ID1
```
vpp# set int l2 bridge host-vpp1vpp2  1
```
检查网桥域1：
```
vpp# show bridge-domain 1 detail
BD-ID   Index   BSN  Age(min)  Learning  U-Forwrd  UU-Flood  Flooding  ARP-Term  BVI-Intf
1       1      0     off        on        on        on        on       off       N/A

        Interface           If-idx ISN  SHG  BVI  TxFlood        VLAN-Tag-Rewrite
    host-vpp1out            1     1    0    -      *                 none
    host-vpp1vpp2           2     1    0    -      *                 none
```

#### 3.2.7.9. 在vpp2上配置环回接口
```
vpp# create loopback interface
loop0
```
将IP地址10.10.1.2/24添加到vpp2接口loop0。将vpp2上的接口loop0的状态设置为“ up”

#### 3.2.7.10. 在vpp2上配置网桥域
检查以查看第一个可用的网桥域ID（在这种情况下为1）

将接口loop0作为桥接虚拟接口（bvi）添加到桥接域1
```
vpp# set int l2 bridge loop0 1 bvi
```
将接口vpp2vpp1添加到网桥域1
```
vpp# set int l2 bridge host-vpp2vpp1  1
```
检查网桥域和接口。

#### 3.2.7.11. 从主机ping到vpp，从vpp到主机

* 1.在vpp1和vpp2上添加跟踪
* 2.从主机ping到10.10.1.2
* 3.检查并清除vpp1和vpp2上的跟踪
* 4.从vpp2 ping到10.10.1.1
* 5.检查并清除vpp1和vpp2上的跟踪

#### 3.2.7.12. 检查l2 fib

```
vpp# show l2fib verbose
Mac Address     BD Idx           Interface           Index  static  filter  bvi   Mac Age (min)
de:ad:00:00:00:00    1            host-vpp1vpp2           2       0       0     0      disabled
c2:f6:88:31:7b:8e    1            host-vpp1out            1       0       0     0      disabled
2 l2fib entries
```

```
vpp# show l2fib verbose
Mac Address     BD Idx           Interface           Index  static  filter  bvi   Mac Age (min)
de:ad:00:00:00:00    1                loop0               2       1       0     1      disabled
c2:f6:88:31:7b:8e    1            host-vpp2vpp1           1       0       0     0      disabled
2 l2fib entries
```

## 3.3. 对用户

**“用户”部分描述了基本的VPP安装和配置操作**。VPP的安装和配置可以手动完成，也可以使用配置实用程序完成。

本节涵盖以下领域：

用户部分涵盖了基本的VPP安装和配置操作。本节涵盖以下领域：

* 描述了不同类型的VPP软件包
* 介绍如何在不同的OS平台（Ubuntu，Centos，openSUSE）上手动安装VPP Binaries
* 说明如何手动配置，然后运行VPP
* 介绍如何安装，然后使用配置实用程序配置VPP

* [配置VPP](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/index.html)
    [大页内存](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/hugepages.html)
    [VPP配置-CLI和'startup.conf'](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html)
* [运行VPP](https://fd.io/docs/vpp/master/gettingstarted/users/running/index.html)
   ['vpp'用户组](https://fd.io/docs/vpp/master/gettingstarted/users/running/index.html#vpp-usergroup)
    [VPP系统文件-'vpp.service'](https://fd.io/docs/vpp/master/gettingstarted/users/running/index.html#vpp-systemd-file-vpp-service)

### 3.3.1. 配置VPP

在运行FD.io VPP之前，需要执行一些基本配置。本节介绍配置过程：

#### 3.3.1.1. 大页内存

VPP需要巨大的页面才能在VPP操作期间运行，以管理大容量的内存。在VPP安装过程中，VPP将覆盖现有的大页面设置。默认情况下，VPP将系统上的大页面数设置为1024 2M个大页面。这是系统上不仅仅由VPP使用的大页面数。

安装VPP后，以下配置文件将复制到系统中。大页面设置适用于VPP安装和系统重新引导。要设置大页面设置，请执行以下命令：

```bash
$ cat /etc/sysctl.d/80-vpp.conf
# 4. Number of 2MB hugepages desired
vm.nr_hugepages=1024

# 5. Must be greater than or equal to (2 * vm.nr_hugepages).
vm.max_map_count=3096

# 6. All groups allowed to access hugepages
vm.hugetlb_shm_group=0

# 7. Shared Memory Max must be greater or equal to the total size of hugepages.
# 8. For 2MB pages, TotalHugepageSize = vm.nr_hugepages * 2 * 1024 * 1024
# 9. If the existing kernel.shmmax setting  (cat /sys/proc/kernel/shmmax)
# 10. is greater than the calculated TotalHugepageSize then set this parameter
# 11. to current shmmax value.
kernel.shmmax=2147483648
```

这部分，我在`10.170.7.166`上已经配置好了大页内存。

根据系统的使用方式，可以更新此配置文件以调整系统上保留的大页面数。以下是一些可能的设置示例。

**对于工作量最少的小型VM：**
```
vm.nr_hugepages=512
vm.max_map_count=2048
kernel.shmmax=1073741824
```
对于运行多个虚拟机的大型系统，每个虚拟机都需要自己的一组大页面：
```
vm.nr_hugepages=32768
vm.max_map_count=66560
kernel.shmmax=68719476736
```

* 注意：如果`VPP在虚拟机（VM）中运行`，则该VM必须具有巨大的页面支持。安装VPP后，它将尝试覆盖现有的大页面设置。如果虚拟机没有巨大的页面支持，则安装将失败，但是失败可能不会引起注意。重新引导VM后，在系统启动时， 将重新应用'vm.nr_hugepages'，并且将失败，并且VM将中止内核引导，从而锁定VM。为了避免这种情况，请确保VM具有足够的大页面支持。

#### 3.3.1.2. VPP配置-`CLI`和`'startup.conf'`

成功安装后，VPP将在`/ etc / vpp /`目录中安装名为`startup.conf`的启动配置文件 。可以定制此文件以使VPP根据需要运行，但包含典型安装的默认值。

以下是有关此文件及其包含的一些参数和值的更多详细信息。

##### 3.3.1.2.1. 命令行参数
在我们描述启动配置文件（startup.conf）的详细信息之前，应该提到可以在没有启动配置文件的情况下启动VPP。

参数按节名称分组。当为一个节提供多个参数时，该节的所有参数都必须用花括号括起来。例如，要通过命令行使用节名称为'unix'的配置数据启动VPP ：

```bash
$ sudo /usr/bin/vpp unix { interactive cli-listen 127.0.0.1:5002 }
```
命令行可以显示为单个字符串或多个字符串。在解析之前，命令行上给出的所有内容都用空格连接成单个字符串。VPP应用程序必须能够找到其自己的可执行映像。确保其工作的最简单方法是通过提供其绝对路径来调用VPP应用程序。例如：` '/ usr / bin / vpp <options>' `在启动时，VPP应用程序首先解析它们自己的ELF节，以创建init，配置和退出处理程序的列表。

使用VPP开发时，在gdb中通常足以启动这样的应用程序：

```
(gdb) run unix interactive
```

##### 3.3.1.2.2. 启动配置文件（startup.conf）

将启动配置指定为VPP的更典型方法是使用启动配置文件（startup.conf）。

该文件的路径在命令行上提供给VPP应用程序。通常在`/etc/vpp/startup.conf`中。如果VPP作为软件包安装，则在此位置提供默认的startup.conf文件。

配置文件的格式是一个简单的文本文件，其内容与命令行相同。

一个非常简单的startup.conf文件：

```
$ cat /etc/vpp/startup.conf
unix {
  nodaemon
  log /var/log/vpp/vpp.log
  full-coredump
  cli-listen localhost:5002
}

api-trace {
  on
}

dpdk {
  dev 0000:03:00.0
}
```

指示VPP使用-c选项加载该文件。例如：
```
$ sudo /usr/bin/vpp -c /etc/vpp/startup.conf
```

##### 3.3.1.2.3. 配置参数

以下是一些节名称及其相关参数的列表。这不是一个详尽的列表，但是应该使您了解如何配置VPP。

对于所有配置参数，请在源代码中搜索`VLIB_CONFIG_FUNCTION`和`VLIB_EARLY_CONFIG_FUNCTION`的实例 。

例如，调用“ `VLIB_CONFIG_FUNCTION（foo_config，“ foo”）`”将使函数“ `foo_config`”接收名为“ foo”的参数块中给出的所有参数：“ `foo {arg1 arg2 arg3…}`”。

##### 3.3.1.2.4. Unix部分
配置VPP启动和行为类型属性，以及所有基于OS的属性。

```json
unix {
  nodaemon
  log /var/log/vpp/vpp.log
  full-coredump
  cli-listen /run/vpp/cli.sock
  gid vpp
}
```

##### 3.3.1.2.5. Nodaemon
不要派生/后台vpp进程。从流程监视器调用VPP应用程序时，通常会出现这种情况。默认在默认的 “ `startup.conf`”文件中设置。

```
nodaemon
```

##### 3.3.1.2.6. nosyslog
禁用syslog并将错误记录到stderr。从流程监视器（如runit或daemontools）调用VPP应用程序时，通常将其服务输出传递到专用日志服务，这通常会附加时间戳并根据需要旋转日志。

```
nosyslog
```

##### 3.3.1.2.7. 互动
将CLI附加到`stdin / out`并提供调试命令行界面。

```
interactive
```

##### 3.3.1.2.8. 日志<文件名>
以文件名记录启动配置和所有后续CLI命令。在人们不记得或不愿意在错误报告中包含CLI命令的情况下非常有用。默认的“ startup.conf”文件是写入“` /var/log/vpp/vpp.log`”的文件。

在VPP 18.04中，默认日志文件位置已从'`/tmp/vpp.log`'移至'`/var/log/vpp/vpp.log`'。VPP代码与文件位置无关。但是，如果启用了SELinux，则需要新位置才能正确标记文件。检查本地“ startup.conf”文件中系统上日志文件的位置。

```
log /var/log/vpp/vpp-debug.log
```

##### 3.3.1.2.9. 执行| 启动配置<文件名>
从文件名读取启动操作配置。文件的内容将像在CLI上输入的那样执行。这两个关键字是同一功能的别名。如果两者都指定，则只有最后一个才会生效。

CLI命令文件可能类似于：
```
$ cat /usr/share/vpp/scripts/interface-up.txt
set interface state TenGigabitEthernet1/0/0 up
set interface state TenGigabitEthernet1/0/1 up
```

参数示例：
```
startup-config /usr/share/vpp/scripts/interface-up.txt
```

##### 3.3.1.2.10. gid <number | 名称>
将有效组ID设置为呼叫进程的输入组ID或组名。

```
gid vpp
```

##### 3.3.1.2.11. 全核心转储
要求Linux内核转储所有内存映射的地址区域，而不仅仅是text + data + bss。

```
full-coredump
```

##### 3.3.1.2.12. 核心转储大小无限制| \<n> G | \<n> M | \<n> K | \<n>
设置coredump文件的最大大小。输入值可以以GB，MB，KB或字节设置，也可以设置为'unlimited'。

```
coredump-size unlimited
```

##### 3.3.1.2.13. cli-listen <ipaddress：port> | <套接字路径>
绑定CLI以侦听TCP端口5002上的地址localhost。这将接受ipaddress：port对或文件系统路径；在后一种情况下，将打开本地Unix套接字。默认的“ startup.conf”文件是打开套接字“ `/run/vpp/cli.sock`”的文件。

```
cli-listen localhost:5002
cli-listen /run/vpp/cli.sock
```

##### 3.3.1.2.14. 斜线模式
在stdin上禁用逐字符I / O。与emacs Mx gud-gdb结合使用时很有用。

```
cli-line-mode
```

##### 3.3.1.2.15. cli-提示\<string>
将CLI提示符配置为字符串，就是命令行提示符。

```
cli-prompt vpp-2
```

##### 3.3.1.2.16. cli-history-limit \<n>
将命令历史记录限制为<n>行。值为0将禁用命令历史记录。默认值：50

```
cli-history-limit 100
```
##### 3.3.1.2.17. cli-banner
在stdin和Telnet连接上禁用登录横幅。

```
cli-no-banner
```


##### 3.3.1.2.18. cli-pager
禁用输出寻呼机。

```
cli-no-pager
```

##### 3.3.1.2.19. cli-pager-buffer-limit \<n>
将寻呼机缓冲区限制为输出的<n>行。值为0将禁用寻呼机。默认值：100000

```
cli-pager-buffer-limit 5000
```

##### 3.3.1.2.20. runtime-dir <目录>
设置运行时目录，这是某些文件（例如套接字文件）的默认位置。默认值基于用于启动VPP的用户ID。通常是'root'，默认为'/ run / vpp /'。否则，默认为'/ run / user / <uid> / vpp /'。

```
runtime-dir /tmp/vpp
```

##### 3.3.1.2.21. poll-sleep-usec \<n>
在主循环轮询之间添加固定睡眠。默认值为0，即不休眠。

```
poll-sleep-usec 100
```

##### 3.3.1.2.22. pidfile <文件名>
将主线程的pid写入给定的文件名。

```
pidfile /run/vpp/vpp1.pid
```

##### 3.3.1.2.23. api-trace部分
尝试了解控制平面已试图要求转发平面执行的操作时，**跟踪，转储和重播控制平面API跟踪的功能**使VPP用起来大为不同。

通常，只需启用API消息跟踪方案即可：

```
api-trace {
  api-trace on
}
```

###### 3.3.1.2.23.1. on | enable
从开始就启用API跟踪捕获，并在应用程序异常终止时安排API跟踪的事后转储。默认情况下，（循环）跟踪缓冲区将配置为捕获256K跟踪。默认的“ startup.conf”文件默认情况下启用了跟踪，除非有很强的理由，否则应保持启用状态。

```
on
```


###### 3.3.1.2.23.2. nitems \<n>
配置循环跟踪缓冲区以包含最后的<n>条目。默认情况下，跟踪缓冲区捕获最后收到的256K API消息。

```
nitems 524288
```

###### 3.3.1.2.23.3. save-api-table <文件名>
将API消息表转储到/ tmp / <文件名>。

```
save-api-table apiTrace-07-04.txt
```

##### 3.3.1.2.24. api段部分
这些值控制与VPP的二进制API接口的各个方面。

默认值如下所示：

```
api-segment {
  gid vpp
}
```

###### 3.3.1.2.24.1. prefix \<path>
将前缀设置为用于共享内存（SHM）段的名称的前缀。默认值为空，这意味着共享内存段直接在SHM目录'/ dev / shm'中创建。值得注意的是，在许多系统上，“ / dev / shm”是指向文件系统中其他位置的符号链接。Ubuntu将其链接到'/ run / shm'。

```
prefix /run/shm
```
###### 3.3.1.2.24.2. uid <number | name>
设置用于设置共享内存段所有权的用户ID或名称。默认为启动VPP的用户（可能是root）。

```
uid root
```
###### 3.3.1.2.24.3. gid <number | name>
设置应用于设置共享内存段所有权的组ID或名称。默认为启动VPP的同一组，可能是root。

```
gid vpp
```

**以下参数仅应由熟悉VPP相互作用的人员设置。**

###### 3.3.1.2.24.4. baseva \<x>
设置SVM全局区域的基地址。如果未设置，则在AArch64上，代码将尝试确定基址。所有其他默认值为0x30000000。

```
baseva 0x20000000
```
###### 3.3.1.2.24.5. global-size \<n>G | \<n>M | \<n>
设置全局内存大小，所有路由器实例之间共享的内存，数据包缓冲区等。如果未设置，则默认为64M。输入值可以GB，MB或字节设置。

```
global-size 2G
```
###### 3.3.1.2.24.6. global-pvt-heap-size \<n>M | size \<n>
设置全局VM专用堆的大小。如果未设置，则默认为128k。输入值可以以MB或字节为单位设置。

```
global-pvt-heap-size size 262144
```
###### 3.3.1.2.24.7. api-pvt-heap-size \<n>M | size \<n>
设置api私有堆的大小。如果未设置，则默认为128k。输入值可以以MB或字节为单位设置。

```
api-pvt-heap-size 1M
```
###### 3.3.1.2.24.8. api-size \<n>M | \<n>G | \<n>
设置API区域的大小。如果未设置，则默认为16M。输入值可以GB，MB或字节设置。

```
api-size 64M
```
##### 3.3.1.2.25. socksvr部分
启用处理二进制API消息的Unix域套接字。参见`…/ vlibmemory / socket_api.c`。如果未设置此参数，则vpp不会通过套接字处理二进制API消息。

```
socksvr {
   # Explicitly name a socket file
   socket-name /run/vpp/api.sock
   or
   # Use defaults as described below
   default
}
```
“ default”关键字指示vpp在以root用户身份运行时使用`/run/vpp/api.sock`，否则将使用`/run/user/<uid>/api.sock`。

##### 3.3.1.2.26. cpu部分
在VPP中，有一个主线程，并且用户可以选择创建工作线程。主线程和工作线程可以手动或自动固定到CPU内核。

```
cpu {
   main-core 1
   corelist-workers 2-3,18-19
}
```

**手动将线程固定到CPU内核**

###### 3.3.1.2.26.1. main-core
设置运行主线程的逻辑CPU内核，如果未设置主内核，则VPP将使用内核1（如果有）

```
main-core 1
```
###### 3.3.1.2.26.2. corelist-workers
设置运行工作线程的逻辑CPU内核

```
corelist-workers 2-3,18-19
```

**自动将线程固定到CPU内核**

###### 3.3.1.2.26.3. skip-cores number
设置要跳过的CPU内核数（1…N-1），跳过的CPU内核不用于固定主线程和工作线程。

主线程自动固定到第一个可用的CPU内核，工作线程固定在分配给主线程的内核之后的下一个空闲CPU内核

```
skip-cores 4
```
###### 3.3.1.2.26.4. workers number
指定要创建的工作线程数将工作线程固定到N个连续的CPU内核，同时跳过“跳过内核” CPU内核和主线程的CPU内核

```
workers 2
```
###### 3.3.1.2.26.5. scheduler-policy other | batch | idle | fifo | rr
设置主线程和工作线程的调度策略和优先级

调度策略选项包括：other （`SCHED_OTHER`），batch （`SCHED_BATCH`）idle（`SCHED_IDLE`），fifo（`SCHED_FIFO`），rr（`SCHED_RR`）

```
scheduler-policy fifo
```
###### 3.3.1.2.26.6. scheduler-priority number
调度优先级仅用于“实时策略（fifo和rr）”，并且必须在特定策略支持的优先级范围内

```
scheduler-priority 50
```

##### 3.3.1.2.27. 缓冲区部分
```
buffers {
   buffers-per-numa 128000
   default data-size 2048
}
```


###### 3.3.1.2.27.1. buffers-per-numa number
增加分配的缓冲区数，只有在具有大量接口和辅助线程的情况下才需要。值是每个numa节点。默认值为16384（如果未特权运行则为8192）

```
buffers-per-numa 128000
```
###### 3.3.1.2.27.2. default data-size number
缓冲区数据区的大小，默认为2048

```
default data-size 2048
```


##### 3.3.1.2.28. dpdk部分
```
dpdk {
   dev default {
      num-rx-desc 512
      num-tx-desc 512
   }

   dev 0000:02:00.1 {
      num-rx-queues 2
      name eth0
   }
}
```

###### 3.3.1.2.28.1. dev \<pci-dev\> | default { .. }
将特定的PCI设备列入白名单（例如尝试驱动）。PCI-dev是形式为“ `DDDD：BB：SS.F`”的字符串，其中：

* DDDD =网域
* BB =总线号码
* SS =插槽号
* F =功能

如果使用关键字default，则这些值将应用于所有设备。

这与Linux sysfs树（即，`/ sys / bus / pci / devices`）中用于PCI设备目录名称的格式相同。

```
dpdk {
   dev default {
      num-rx-desc 512
      num-tx-desc 512
   }
```
###### 3.3.1.2.28.2. dev \<pci-dev\> { .. }
通过指定PCI地址将特定接口列入白名单。通过指定PCI地址将特定接口列入白名单时，还可以指定其他自定义参数。有效选项包括：

```
dev 0000:02:00.0
dev 0000:03:00.0
```
###### 3.3.1.2.28.3. blacklist \<pci-dev\>
通过指定PCI供应商将特定设备类型列入黑名单：设备白名单条目优先

```
blacklist 8086:10fb
```
###### 3.3.1.2.28.4. name interface-name
设置接口名称

```
dev 0000:02:00.1 {
   name eth0
}
```
###### 3.3.1.2.28.5. num-rx-queues \<n\>
接收队列数。还启用RSS。预设值为1。

```
dev 0000:02:00.1 {
   num-rx-queues <n>
}
```
###### 3.3.1.2.28.6. num-tx-queues \<n\>
传输队列数。默认值等于工作线程数，如果没有工作线程，则默认为1。

```
dev 000:02:00.1 {
   num-tx-queues <n>
}
```
###### 3.3.1.2.28.7. num-rx-desc \<n\>
接收环中描述符的数量。增加或减少数量可能会影响性能。默认值为1024。

```
dev 000:02:00.1 {
   num-rx-desc <n>
}
```
###### 3.3.1.2.28.8. vlan-strip-offload on | off
接口的VLAN Strip卸载模式。默认情况下，使用ENIC驱动程序对除VIC以外的所有NIC的VLAN剥离均关闭，该驱动程序默认情况下已启用VLAN剥离。

```
dev 000:02:00.1 {
   vlan-strip-offload on|off
}
```
###### 3.3.1.2.28.9. uio-driver driver-name
更改VPP使用的UIO驱动程序，选项为：`igb_uio`，`vfio-pci`，`uio_pci_generic`或`auto`（默认）

```
uio-driver vfio-pci
```
###### 3.3.1.2.28.10. no-multi-seg
禁用多段缓冲区，提高性能，但禁用巨型MTU支持

```
no-multi-seg
```
###### 3.3.1.2.28.11. socket-mem \<n\>
更改每个socket的大页内存分配，仅在需要大量mbuf时才需要。每个检测到的CPU插槽的默认值为256M

```
socket-mem 2048,2048
```
###### 3.3.1.2.28.12. no-tx-checksum-offload
禁用UDP / TCP TX校验和卸载。通常需要使用更快的矢量PMD（以及非多段）

```
no-tx-checksum-offload
```
###### 3.3.1.2.28.13. enable-tcp-udp-checksum
启用UDP / TCP TX校验和卸载这是'no-tx-checksum-offload'的反向选项

```
enable-tcp-udp-checksum
```
##### 3.3.1.2.29. 插件部分
配置VPP插件。

```
plugins {
   path /ws/vpp/build-root/install-vpp-native/vpp/lib/vpp_plugins
   plugin dpdk_plugin.so enable
}
```
###### 3.3.1.2.29.1. path pathname
根据VPP插件的位置调整插件路径。

```
path /ws/vpp/build-root/install-vpp-native/vpp/lib/vpp_plugins
```
###### 3.3.1.2.29.2. plugin plugin-name | default enable | disable
默认情况下禁用所有插件，然后有选择地启用特定插件

```
plugin default disable
plugin dpdk_plugin.so enable
plugin acl_plugin.so enable
```
默认情况下启用所有插件，然后有选择地禁用特定插件

```
plugin dpdk_plugin.so disable
plugin acl_plugin.so disable
```


##### 3.3.1.2.30. 统计部分
```
statseg {
   per-node-counters on
 }
```


##### 3.3.1.2.31. socket-name \<filename>
统计段套接字的名称默认为`/run/vpp/stats.sock`。

```
socket-name /run/vpp/stats.sock
```
##### 3.3.1.2.32. size <nnn>[KMG]
统计数据段的大小，默认为32mb

```
size 1024M
```
##### 3.3.1.2.33. per-node-counters on | off
默认为无

`per-node-counters on`
##### 3.3.1.2.34. update-interval \<f64-seconds>
设置片段抓取/更新间隔

```
update-interval 300
```

**一些高级参数：**

##### 3.3.1.2.35. acl插件部分
这些参数更改**ACL（访问控制列表）**插件的配置，例如ACL双哈希表的初始化方式。

仅应由熟悉VPP和ACL插件相互作用的人员设置。

前三个参数（连接哈希存储桶，连接哈希内存和连接计数最大值）设置每个接口的连接表参数， 以修改IPv6的两个有界索引可扩展哈希表（40 * 8位密钥和8 * 8位）值对）和IPv4（16 * 8位密钥和8 * 8位值对）的ACL插件FA接口会话 被初始化。


###### 3.3.1.2.35.1. connection hash buckets \<n>
设置两个双向哈希表中的每个哈希桶的数量（四舍五入为2的幂）。默认为64 * 1024（65536）哈希存储桶。

```
connection hash buckets 65536
```
###### 3.3.1.2.35.2. connection hash memory \<n>
为两个双向哈希表中的每一个设置分配的内存大小（以字节为单位）。默认为1073741824字节

```
connection hash memory 1073741824
```
###### 3.3.1.2.35.3. connection count max \<n>
为两个双哈希表分配每个工作人员的会话池时，设置池元素的最大数量。每个池中默认为500000个元素。

```
connection count max 500000
```
###### 3.3.1.2.35.4. main heap size \<n>G | \<n>M | \<n>K | \<n>
设置保存所有ACL模块相关分配的主内存堆的大小（散列除外）。默认大小为0，但在ACL堆期间初始化等于 `per_worker_size_with_slack * tm-> n_vlib_mains + bihash_size + main_slack`。请注意，这些变量部分基于上面提到的 连接表每个接口参数。

```
main heap size 3G
```
接下来的三个参数，即哈希查找堆大小，哈希查找哈希桶和哈希查找哈希内存，将修改ACL插件使用的双向哈希查找表的初始化。尝试将ACL应用于在数据包处理期间查找的ACL的现有向量时，会初始化此表（但发现该表不存在/尚未初始化。）
###### 3.3.1.2.35.5. hash lookup heap size \<n>G | \<n>M | \<n> K | \<n>
设置内存堆的大小，该内存堆保存与基于散列的查找有关的所有其他分配。默认大小为67108864字节。

```
hash lookup heap size 70M
```
###### 3.3.1.2.35.6. hash lookup hash buckets \<n>
设置双向哈希表中的哈希桶数（四舍五入为2的幂）。默认为65536个哈希存储桶。

```
hash lookup hash buckets 65536
```
###### 3.3.1.2.35.7. hash lookup hash memory \<n>
设置为双哈希查找表分配的内存大小（以字节为单位）。默认为67108864字节

```
hash lookup hash memory 67108864
```
###### 3.3.1.2.35.8. use tuple merge \<n>
设置一个布尔值，该布尔值指示是否将TupleMerge用于哈希ACL。默认值为1（true），这意味着哈希ACL的默认实现确实使用TupleMerge。

```
use tuple merge 1
```
###### 3.3.1.2.35.9. tuple merge split threshold \<n>
设置在将表拆分为两个新表之前，可以在双向哈希表中冲突的最大规则（ACE）。拆分可通过基于它们的公共元组（通常是它们的最大公共元组）对冲突规则进行散列来确保较少的规则冲突。当冲突规则向量的长度大于此阈值量时，就会发生拆分 。默认情况下，每个表最多39个规则冲突。

```
tuple merge split threshold 30
```
###### 3.3.1.2.35.10. reclassify sessions \<n>
设置一个布尔值，该值指示在处理重新应用ACL或更改已应用的ACL时是否考虑会话的时期。默认值为0（false），这意味着默认实现不考虑会话的时期。

```
reclassify sessions 1
```
##### 3.3.1.2.36. api-queue部分

###### 3.3.1.2.36.1. length \<n>
设置api队列的长度。有效队列的最小长度为1024，这也是默认值。

```
length 2048
```

##### 3.3.1.2.37. [cj Section](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html#cj-section)

**`TODO`**

##### 3.3.1.2.38. [dns Section](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html#dns-section)

**`TODO`**


##### 3.3.1.2.39. [ethernet Section](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html#ethernet-section)

**`TODO`**

###### 3.3.1.2.39.1. default-mtu \<n>
指定以太网接口的默认MTU大小。必须在64-9000范围内。默认值为9000。

```
default-mtu 1500
```

##### 3.3.1.2.40. [heapsize Section](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html#heapsize-section)

**`TODO`**

##### 3.3.1.2.41. [ip Section](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html#ip-section)

**`TODO`**

##### 3.3.1.2.42. [ip6 Section](https://fd.io/docs/vpp/master/gettingstarted/users/configuring/startup.html#ip6-section)

**`TODO`**

##### 3.3.1.2.43. vlib Section
这些参数配置VLIB，例如允许您选择是启用内存跟踪还是事后日志转储。

###### 3.3.1.2.43.1. memory-trace
启用内存跟踪（mheap追溯）。默认值为0，表示禁用内存跟踪。

```
memory-trace
```
###### 3.3.1.2.43.2. elog-events \<n>
设置事件环（事件的循环缓冲区）的元素/事件数（大小）。此数字舍入为2的幂。默认为131072（128 << 10）个元素。

```
elog-events 4096
```
###### 3.3.1.2.43.3. elog-post-mortem-dump
启用尝试将事后日志转储到 / tmp / elog_post_mortem。如果调用了os_panic或os_exit，则<PID_OF_CALLING_PROCESS>。

```
elog-post-mortem-dump
```

##### 3.3.1.2.44. **`TODO`**




### 3.3.2. 运行VPP
#### 3.3.2.1. 'vpp'用户组
安装VPP后，将创建一个新的用户组'vpp'。为避免以root用户身份运行VPP CLI（vppctl），请将需要与VPP进行交互的所有现有用户添加到新组中：

```
$ sudo usermod -a -G vpp user1
```
更新您的当前会话以使组更改生效：

```
$ newgrp vpp
```

#### 3.3.2.2. VPP系统文件-'`vpp.service`'
安装VPP后，还将安装systemd服务文件。此文件vpp.service（Ubuntu：/lib/systemd/system/vpp.service和CentOS：/usr/lib/systemd/system/vpp.service）控制如何将VPP作为服务运行。例如，是否在发生故障时重新启动，如果有，则延迟多少时间。另外，应加载哪个UIO驱动程序以及“ startup.conf” 文件的位置。

```
$ cat /usr/lib/systemd/system/vpp.service
[Unit]
Description=Vector Packet Processing Process
After=syslog.target network.target auditd.service

[Service]
ExecStartPre=-/bin/rm -f /dev/shm/db /dev/shm/global_vm /dev/shm/vpe-api
ExecStartPre=-/sbin/modprobe uio_pci_generic
ExecStart=/usr/bin/vpp -c /etc/vpp/startup.conf
Type=simple
Restart=on-failure
RestartSec=5s

[Install]
WantedBy=multi-user.target
```

* 注意：某些“ `uio_pci_generic`”驱动程序的较旧版本无法正确绑定所有受支持的NIC，因此需要安装从`DPDK`构建的“ `igb_uio`”驱动程序。此文件控制在引导时加载哪个驱动程序。 'startup.conf'文件控制使用哪个驱动程序。


## 3.4. 对开发人员

开发人员部分涵盖以下领域：

* 描述如何构建不同类型的VPP图像
* 通过一些GDB示例，说明如何在有和没有GDB的情况下运行VPP
* 描述了审核和合并补丁所需的步骤
* 描述VPP软件体系结构并标识关联的四个VPP层
* 描述与每个VPP层相关的不同组件
* 介绍如何创建，添加，启用/禁用不同的ARC功能
* 讨论了绑定索引可扩展哈希（bihash）的不同方面，以及如何在数据库查找中使用它
* 描述了不同类型的API支持以及如何集成插件

### 3.4.1. 构建VPP
要开始使用VPP进行开发，您需要获取所需的VPP源，然后构建软件包。有关构建系统的更多详细信息，请参阅Build System。

#### 3.4.1.1. 设置代理
根据您所使用的环境，可能需要设置代理。运行以下代理命令以指定代理服务器名称和相应的端口号：

```
$ export http_proxy=http://<proxy-server-name>.com:<port-number>
$ export https_proxy=https://<proxy-server-name>.com:<port-number>
```
#### 3.4.1.2. 获取VPP来源
要获取用于创建内部版本的VPP源，请运行以下命令：

```
$ git clone https://gerrit.fd.io/r/vpp
$ cd vpp
```
#### 3.4.1.3. 建立VPP依赖关系
在构建VPP映像之前，通过输入以下命令，确保没有安装FD.io VPP或DPDK软件包：

```
$ dpkg -l | grep vpp
$ dpkg -l | grep DPDK
```
运行上述命令后，应该没有输出或没有显示任何程序包。

运行以下make命令以安装FD.io VPP的依赖项。

如果下载在任何时候都挂起，则可能需要 设置代理才能使下载正常工作。

```
$ make install-dep
Hit:1 http://us.archive.ubuntu.com/ubuntu xenial InRelease
Get:2 http://us.archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]
Get:3 http://security.ubuntu.com/ubuntu xenial-security InRelease [107 kB]
Get:4 http://us.archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
Get:5 http://us.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [803 kB]
Get:6 http://us.archive.ubuntu.com/ubuntu xenial-updates/main i386 Packages [732 kB]
...
...
Update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode
Setting up default-jdk-headless (2:1.8-56ubuntu2) ...
Processing triggers for libc-bin (2.23-0ubuntu3) ...
Processing triggers for systemd (229-4ubuntu6) ...
Processing triggers for ureadahead (0.100.0-19) ...
Processing triggers for ca-certificates (20160104ubuntu1) ...
Updating certificates in /etc/ssl/certs...
0 added, 0 removed; done.
Running hooks in /etc/ca-certificates/update.d...

done.
done.
```
#### 3.4.1.4. 生成VPP（调试）
此构建版本包含调试符号，这些调试符号对于修改VPP非常有用。下面的 make命令可构建VPP的调试版本。生成调试映像时，二进制文件可以在/ build-root / vpp_debug-native中找到。

调试内部版本包含调试符号，这些符号对于故障排除或修改VPP非常有用。下面的make命令可生成VPP的调试版本。可以在/ build-root / vpp_debug-native中找到用于构建调试映像的二进制文件。

```
$ make build
make[1]: Entering directory '/home/vagrant/vpp-master/build-root'
@@@@ Arch for platform 'vpp' is native @@@@
@@@@ Finding source for dpdk @@@@
@@@@ Makefile fragment found in /home/vagrant/vpp-master/build-data/packages/dpdk.mk @@@@
@@@@ Source found in /home/vagrant/vpp-master/dpdk @@@@
@@@@ Arch for platform 'vpp' is native @@@@
@@@@ Finding source for vpp @@@@
@@@@ Makefile fragment found in /home/vagrant/vpp-master/build-data/packages/vpp.mk @@@@
@@@@ Source found in /home/vagrant/vpp-master/src @@@@
...
...
make[5]: Leaving directory '/home/vagrant/vpp-master/build-root/build-vpp_debug-native/vpp/vpp-api/java'
make[4]: Leaving directory '/home/vagrant/vpp-master/build-root/build-vpp_debug-native/vpp/vpp-api/java'
make[3]: Leaving directory '/home/vagrant/vpp-master/build-root/build-vpp_debug-native/vpp'
make[2]: Leaving directory '/home/vagrant/vpp-master/build-root/build-vpp_debug-native/vpp'
@@@@ Installing vpp: nothing to do @@@@
make[1]: Leaving directory '/home/vagrant/vpp-master/build-root'
```
#### 3.4.1.5. `生成VPP`（发行版）
本节介绍如何构建FD.io VPP的常规发行版。该发行版本经过优化，不会创建任何调试符号。可在/ build-root / vpp-native中找到用于构建发行映像的二进制文件。

在下面使用以下make命令来构建FD.io VPP的发行版本。

```
$ make build-release
```
#### 3.4.1.6. 构建必要的软件包
需要构建的软件包取决于VPP将在其上运行的系统类型：

* 在Debian软件包如果VPP是要在Ubuntu上运行是建立
* 该RPM软件包内置如果VPP是要在CentOS或红帽运行

#### 3.4.1.7. 构建Debian软件包
要构建debian软件包，请使用以下命令：

```
$ make pkg-deb
```
#### 3.4.1.8. 建立RPM套件
要生成rpm软件包，请根据系统使用以下命令之一：

```
$ make pkg-rpm
```
一旦构建了软件包，就可以在build-root目录中找到它们。

```
$ ls *.deb

If the packages are built correctly, then this should be the corresponding output:

vpp_18.07-rc0~456-gb361076_amd64.deb             vpp-dbg_18.07-rc0~456-gb361076_amd64.deb
vpp-dev_18.07-rc0~456-gb361076_amd64.deb         vpp-api-lua_18.07-rc0~456-gb361076_amd64.deb
vpp-lib_18.07-rc0~456-gb361076_amd64.deb         vpp-api-python_18.07-rc0~456-gb361076_amd64.deb
vpp-plugins_18.07-rc0~456-gb361076_amd64.deb
```
最后，可以使用以下命令安装创建的软件包。安装与VPP将在其上运行的操作系统相对应的软件包：

对于Ubuntu：

```
$ sudo bash
# 4. dpkg -i *.deb
```
对于Centos或Redhat：

```
$ sudo bash
# 4. rpm -ivh *.rpm
```

### 3.4.2. 运行VPP

构建VPP二进制文件后，您现在已构建了多个映像。当您需要运行VPP而不安装软件包时，这些映像很有用。例如，如果要与GDB一起运行VPP。

#### 3.4.2.1. 在没有GDB的情况下运行
要运行没有GDB构建的VPP映像，请运行以下命令：

运行发布映像：

```
# 4. make run-release
#
```
运行调试映像：

```
# 4. make run
#
```

#### 3.4.2.2. 与GDB一起运行
使用以下命令，您可以运行VPP，然后将其放入GDB提示符。

运行发布映像：

```
# 4. make debug-release
(gdb)
```
运行调试映像：

```
# 4. make debug
(gdb)
```

#### 3.4.2.3. GDB范例
在本节中，我们有一些有用的gdb命令。

##### 3.4.2.3.1. 启动GDB
在gdb提示符下，可以通过运行以下命令来启动VPP：

```
(gdb) run -c /etc/vpp/startup.conf
Starting program: /scratch/vpp-master/build-root/install-vpp_debug-native/vpp/bin/vpp -c /etc/vpp/startup.conf
 [Thread debugging using libthread_db enabled]
 Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".
 vlib_plugin_early_init:361: plugin path /scratch/vpp-master/build-root/install-vpp_debug-native/vpp/lib/vpp_plugins:/scratch/vpp-master/build-root/install-vpp_debug-native/vpp/lib/vpp_plugins
 ....
```
##### 3.4.2.3.2. 回溯
如果您在运行VPP时遇到错误，例如由于段错误或中止信号而导致VPP终止，则可以运行VPP调试二进制文件，然后执行backtrace或bt。

```
(gdb) bt
#0  ip4_icmp_input (vm=0x7ffff7b89a40 <vlib_global_main>, node=0x7fffb6bb6900, frame=0x7fffb6725ac0) at /scratch/vpp-master/build-data/../src/vnet/ip/icmp4.c:187
#1  0x00007ffff78da4be in dispatch_node (vm=0x7ffff7b89a40 <vlib_global_main>, node=0x7fffb6bb    6900, type=VLIB_NODE_TYPE_INTERNAL, dispatch_state=VLIB_NODE_STATE_POLLING, frame=0x7fffb6725ac0, last_time_stamp=10581236529    65565) at /scratch/vpp-master/build-data/../src/vlib/main.c:988
#2  0x00007ffff78daa77 in dispatch_pending_node (vm=0x7ffff7b89a40 <vlib_global_main>, pending_frame_index=6, last_time_stamp=1058123652965565) at /scratch/vpp-master/build-data/../src/vlib/main.c:1138
....
```

##### 3.4.2.3.3. 进入GDB提示
当VPP运行时，您可以通过按CTRL + C进入命令提示符。

##### 3.4.2.3.4. 断点
在GDB提示符下，通过运行以下命令来设置断点：

```
(gdb) break ip4_icmp_input
Breakpoint 4 at 0x7ffff6b9c00b: file /scratch/vpp-master/build-data/../src/vnet/ip/icmp4.c, line 142.
```
列出已经设置的断点：
```
(gdb) i b
Num     Type           Disp Enb Address            What
1       breakpoint     keep y   0x00007ffff6b9c00b in ip4_icmp_input at /scratch/vpp-master/build-data/../src/vnet/ip/icmp4.c:142
    breakpoint already hit 3 times
2       breakpoint     keep y   0x00007ffff6b9c00b in ip4_icmp_input at /scratch/vpp-master/build-data/../src/vnet/ip/icmp4.c:142
3       breakpoint     keep y   0x00007ffff640f646 in tw_timer_expire_timers_internal_1t_3w_1024sl_ov
    at /scratch/vpp-master/build-data/../src/vppinfra/tw_timer_template.c:775
```

##### 3.4.2.3.5. 删除断点
```
(gdb) del 2
(gdb) i b
Num     Type           Disp Enb Address            What
1       breakpoint     keep y   0x00007ffff6b9c00b in ip4_icmp_input at /scratch/vpp-master/build-data/../src/vnet/ip/icmp4.c:142
    breakpoint already hit 3 times
3       breakpoint     keep y   0x00007ffff640f646 in tw_timer_expire_timers_internal_1t_3w_1024sl_ov
    at /scratch/vpp-master/build-data/../src/vppinfra/tw_timer_template.c:775
```

##### 3.4.2.3.6. Step/Next/List
使用（s）tep into，（n）ext逐步遍历代码，并在list所在位置的前后列出一些行。

```
Thread 1 "vpp_main" hit Breakpoint 1, ip4_icmp_input (vm=0x7ffff7b89a40 <vlib_global_main>, node=0x7fffb6bb6900, frame=0x7fffb6709480)
    at /scratch/jdenisco/vpp-master/build-data/../src/vnet/ip/icmp4.c:142
142 {
(gdb) n
143   icmp4_main_t *im = &icmp4_main;
(
(gdb) list
202       vlib_put_next_frame (vm, node, next, n_left_to_next);
203     }
204
205   return frame->n_vectors;
206 }
207
208 /* *INDENT-OFF* */
209 VLIB_REGISTER_NODE (ip4_icmp_input_node,static) = {
210   .function = ip4_icmp_input,
211   .name = "ip4-icmp-input",
```

##### 3.4.2.3.7. 检查数据和数据包
要查看数据和数据包，请使用e（x）胺或（p）rint。

例如，在此代码中查看ip数据包：

```
(gdb) p/x *ip0
$3 = {{ip_version_and_header_length = 0x45, tos = 0x0, length = 0x5400,
fragment_id = 0x7049, flags_and_fragment_offset = 0x40, ttl = 0x40, protocol = 0x1,
checksum = 0x2ddd, {{src_address = {data = {0xa, 0x0, 0x0, 0x2},
data_u32 = 0x200000a, as_u8 = {0xa, 0x0, 0x0, 0x2}, as_u16 = {0xa, 0x200},
as_u32 = 0x200000a}, dst_address = {data = {0xa, 0x0, 0x0, 0xa}, data_u32 = 0xa00000a,
as_u8 = {0xa, 0x0, 0x0, 0xa}, as_u16 = {0xa, 0xa00},  as_u32 = 0xa00000a}},
address_pair = {src = {data = {0xa, 0x0, 0x0, 0x2}, data_u32 = 0x200000a,
as_u8 = {0xa, 0x0, 0x0, 0x2}, as_u16 = {0xa, 0x200},  as_u32 = 0x200000a},
dst = {data = {0xa, 0x0, 0x0, 0xa}, data_u32 = 0xa00000a, as_u8 = {0xa, 0x0, 0x0, 0xa},
as_u16 = {0xa, 0xa00}, as_u32 = 0xa00000a}}}}, {checksum_data_64 =
{0x40704954000045, 0x200000a2ddd0140}, checksum_data_64_32 = {0xa00000a}},
{checksum_data_32 = {0x54000045, 0x407049, 0x2ddd0140, 0x200000a, 0xa00000a}}}
```
然后是icmp标头

```
(gdb) p/x *icmp0
$4 = {type = 0x8, code = 0x0, checksum = 0xf148}
```
然后查看实际字节：

```
(gdb) x/50w ip0
0x7fde9953510e:     0x54000045      0x00407049      0x2ddd0140      0x0200000a
0x7fde9953511e:     0x0a00000a      0xf1480008      0x03000554      0x5b6b2e8a
0x7fde9953512e:     0x00000000      0x000ca99a      0x00000000      0x13121110
0x7fde9953513e:     0x17161514      0x1b1a1918      0x1f1e1d1c    
```

### 3.4.3. 添加插件
#### 3.4.3.1. 总览
本节说明VPP开发人员如何创建新插件并将其添加到VPP。我们假设我们从VPP <工作区顶部>开始。

作为一个例子，我们将使用make-plugin.sh中发现的工具 ./extras/emacs。make-plugin.sh是由一组emacs-lisp框架构造的综合插件生成器的简单包装。
#### 3.4.3.2. 将目录更改为./src/plugins，然后运行插件生成器：

```
$ cd ./src/plugins
$ ../../extras/emacs/make-plugin.sh
<snip>
Loading /scratch/vpp-docs/extras/emacs/tunnel-c-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/tunnel-decap-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/tunnel-encap-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/tunnel-h-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/elog-4-int-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/elog-4-int-track-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/elog-enum-skel.el (source)...
Loading /scratch/vpp-docs/extras/emacs/elog-one-datum-skel.el (source)...
Plugin name: myplugin
Dispatch type [dual or qs]: dual
(Shell command succeeded with no output)

OK...
```
插件生成器脚本会问两个问题：插件的名称以及要使用的两种调度类型中的哪一种。由于插件名称进入了很多地方-文件名，typedef名称，图形弧名称-值得思考一下。

调度类型是指用于构造node.c（即形式数据平面节点）的编码模式 。对偶选项构造具有推测性排队的双单环对。这是用于负载存储密集图节点的传统编码模式。

所述适量选项生成其使用`vlib_get_buffers`一个四单环路对（...）和`vlib_buffer_enqueue_to_next（...）`。这些运算符充分利用了可用的SIMD向量单元运算。如果您决定稍后将四单循环对更改为双单循环对，则非常简单。

#### 3.4.3.3. 生成的文件
这是生成的文件。我们待会儿会通过它们。

```
$ cd ./myplugin
$ ls
CMakeLists.txt        myplugin.c           myplugin_periodic.c  setup.pg
myplugin_all_api_h.h  myplugin.h           myplugin_test.c
myplugin.api          myplugin_msg_enum.h  node.c
```
由于最近构建系统的改进，你并不需要接触任何其他文件到您的新插件集成到VPP构建。只需从头开始重建工作空间，就会出现新的插件。

#### 3.4.3.4. 重建工作区
这是重新配置和重建工作空间的直接方法：
```
$ cd <top-of-workspace>
$ make rebuild [or rebuild-release]
```
多亏了ccache，该操作不会花费很多时间。

#### 3.4.3.5. 健全性检查：运行vpp

为了快速进行完整性检查，请运行vpp并确保已加载“ myplugin_plugin.so”和“ myplugin_test_plugin.so”：

```
$ cd <top-of-workspace>
$ make run
<snip>
load_one_plugin:189: Loaded plugin: myplugin_plugin.so (myplugin description goes here)
<snip>
load_one_vat_plugin:67: Loaded plugin: myplugin_test_plugin.so
<snip>
DBGvpp#
```
如果此简单测试失败，请寻求帮助。

#### 3.4.3.6. 详细生成的文件

本节将详细讨论生成的文件。可以略过本节，然后再返回以获取更多详细信息。

##### 3.4.3.6.1. CMakeLists.txt
这是用于构建插件的构建系统配方。请修正版权声明：

```
# 4. Copyright (c) <current-year> <your-organization>
```
其余的构建方法非常简单：
```
add_vpp_plugin (myplugin
SOURCES
myplugin.c
node.c
myplugin_periodic.c
myplugin.h

MULTIARCH_SOURCES
node.c

API_FILES
myplugin.api

INSTALL_HEADERS
myplugin_all_api_h.h
myplugin_msg_enum.h

API_TEST_SOURCES
myplugin_test.c
)
```
如您所见，构建配方由几个文件列表组成。SOURCES是C源文件的列表。API_FILES是插件的二进制API定义文件的列表（此文件通常很多），依此类推。

MULTIARCH_SOURCES列出了认为对性能至关重要的数据平面图节点调度功能源文件。这些文件中的特定功能会被多次编译，以便它们可以利用特定于CPU的功能。稍后对此进行更多讨论。

如果添加源文件，只需将它们添加到指定的列表中即可。

##### 3.4.3.6.2. myplugin.h
这是新插件的主要#include文件。除其他外，它定义了插件的main_t数据结构。这是添加特定于问题的数据结构的正确位置。请抵制在插件中创建一组静态或[更糟]全局变量的诱惑。裁判插件之间的名称冲突并不是任何人的好时机。

##### 3.4.3.6.3. myplugin.c
为了缺少更好的描述方式，myplugin.c是vpp插件的“ main.c”等效项。它的工作是将插件挂接到vpp二进制API消息调度程序中，并将其消息添加到vpp的全局“ message-name_crc”哈希表中。请参见“ myplugin_init（…”）”

Vpp本身使用dlsym（…）来跟踪由`VLIB_PLUGIN_REGISTER`宏生成的vlib_plugin_registration_t：

```
VLIB_PLUGIN_REGISTER () =
  {
    .version = VPP_BUILD_VER,
    .description = "myplugin plugin description goes here",
  };
```
Vpp仅从插件目录中加载包含该数据结构实例的.so文件。

您可以从命令行启用或禁用特定的vpp插件。默认情况下，插件已加载。若要更改该行为，请在宏VLIB_PLUGIN_REGISTER中设置default_disabled：
```
VLIB_PLUGIN_REGISTER () =
  {
    .version = VPP_BUILD_VER,
    .default_disabled = 1
    .description = "myplugin plugin description goes here",
  };
```
样板生成器将图形节点分配功能放置到“设备输入”特征弧上。这可能有用也可能没有用。
```
VNET_FEATURE_INIT (myplugin, static) =
{
  .arc_name = "device-input",
  .node_name = "myplugin",
  .runs_before = VNET_FEATURES ("ethernet-input"),
};
```

如插件生成器所给出的那样，myplugin.c包含二进制API消息处理程序，用于通用的“请在这样的接口上启用我的功能”二进制API消息。如您所见，设置vpp消息API表很简单。大警告：该方案不能容忍小错误。示例：忘记添加mainp-> msg_id_base可能导致非常混乱的失败。

如果您坚持谨慎地修改生成的样板-而不是尝试根据首要原理来构建代码-您将节省很多时间和麻烦

##### 3.4.3.6.4. myplugin_test.c
该文件包含二进制API消息生成代码，该代码被编译成单独的.so文件。“ vpp_api_test”程序将加载这些插件，从而立即访问您的插件API，以进行外部客户端二进制API测试。

vpp本身会加载测试插件，并通过“ binary-api”调试CLI使代码可用。这是在集成测试之前对二进制API进行单元测试的一种常用方法。

##### 3.4.3.6.5. node.c
`这是生成的图节点分派函数`。您需要重写它来解决当前的问题。保留节点分发功能的结构将节省大量时间和麻烦。

即使是专家，也要浪费时间来重新构造循环结构，排队模式等等。只需撕下并用与您要解决的问题相关的代码替换样本1x，2x，4x数据包处理代码即可。

#### 3.4.3.7. 插件是“有好处的朋友”

在vpp VLIB_INIT_FUNCTION函数中，通常可以看到特定的init函数调用其他init函数：

```c
if ((error = vlib_call_init_function (vm, some_other_init_function))
   return error;
```
如果一个插件需要在另一个插件中调用init函数，请使用vlib_call_plugin_init_function宏：
```c
if ((error = vlib_call_plugin_init_function (vm, "otherpluginname", some_init_function))
   return error;
```
这允许在插件初始化函数之间进行排序。

如果您希望获得指向另一个插件中的符号的指针，请使用`vlib_plugin_get_symbol（…）`API：

```c
void *p = vlib_get_plugin_symbol ("plugin_name", "symbol");
```
更多例子
有关更多信息，您可以阅读目录“ ./src/plugins”中的许多示例插件。

### 3.4.4. [审核补丁](https://fd.io/docs/vpp/master/gettingstarted/developers/gitreview.html#getting-a-patch-reviewed)

**`TODO`**


### 3.4.5. 软件架构

fd.io vpp实现是第三代矢量数据包处理实现，具体涉及美国专利7,961,636和早期的工作。请注意，Apache-2许可证专门授予非专有的专利许可证；我们将这项专利作为历史关注点。

为了提高性能，vpp数据平面由转发节点的有向图组成，该转发图每次调用处理多个数据包。这种模式可实现多种微处理器优化：流水线和预取以覆盖相关的读取延迟，固有的I缓存阶段行为，矢量指令。除了硬件输入和硬件输出节点之外，整个转发图都是可移植的代码。

根据当前的情况，我们经常启动多个工作线程，这些工作线程使用相同的转发图副本处理来自多个队列的进入哈希数据包

#### 3.4.5.1. VPP层-实施分类法
![VPP层-实施分类法](_v_images/20200907152226718_3254.png =1139x)

* VPP Infra-VPP基础结构层，其中包含核心库源代码。该层执行存储功能，与向量和环配合使用，在哈希表中执行键查找，并与用于调度图形节点的计时器一起使用。
* VLIB-向量处理库。vlib层还处理各种应用程序管理功能：缓冲区，内存和图形节点管理，维护和导出计数器，线程管理，数据包跟踪。Vlib实现了调试CLI（命令行界面）。
* VNET-与VPP的网络接口（第2层，第3层和第4层）配合使用，执行会话和流量管理，并与设备和数据控制平面配合使用。
* Plugins-包含越来越丰富的数据平面插件集，如上图所示。
* VPP-与以上所有内容链接的容器应用程序。
重要的是要对每一层都有一定的了解。最好在API级别处理大多数实现，否则就不去管它了。

##### 3.4.5.1.1. [VPPINFRA（基础设施）](https://fd.io/docs/vpp/master/gettingstarted/developers/infrastructure.html#vppinfra-infrastructure)

与VPP基础结构层关联的文件位于./src/vppinfra文件夹中。

VPPinfra是基本c库服务的集合，足以建立直接在裸机上运行的独立程序。它还提供高性能的动态数组，哈希，位图，高精度的实时时钟支持，细粒度的事件记录和数据结构序列化。

关于vppinfra的一个合理的评论/合理的警告：您不能总是仅通过名称来从普通函数中的内联函数中告诉宏。宏通常用于避免函数调用，并引起（有意的）副作用。

详细介绍请参见：[VPPINFRA](https://fd.io/docs/vpp/master/gettingstarted/developers/infrastructure.html)

**`TODO`**

##### 3.4.5.1.2. [VLIB（矢量处理库）](https://fd.io/docs/vpp/master/gettingstarted/developers/vlib.html#vlib-vector-processing-library)

与vlib关联的文件位于./src/{vlib，vlibapi，vlibmemory}文件夹中。这些库提供矢量处理支持，包括图形节点调度，可靠的多播支持，超轻量协作多任务线程，CLI，插件.DLL支持，物理内存和Linux epoll支持。

详细介绍请参见：[VLIB](https://fd.io/docs/vpp/master/gettingstarted/developers/vlib.html)

**`TODO`**


##### 3.4.5.1.3. [VNET（VPP网络堆栈）](https://fd.io/docs/vpp/master/gettingstarted/developers/vnet.html#vnet-vpp-network-stack)

与VPP网络堆栈层关联的文件位于 ./src/vnet文件夹中。网络堆栈层基本上是其他层中代码的实例化。该层具有vnet库，该库提供矢量化的第2层和3个网络图节点，数据包生成器和数据包跟踪器。

在构建数据包处理应用程序方面，vnet提供了独立于平台的子图，一个子图连接了两个设备驱动程序节点。

典型的RX连接包括“以太网输入”（完整的软件分类，提供ipv4-input，ipv6-input，arp-input等）和“ ipv4-input-no-checksum” [如果硬件可以分类，请执行ipv4标头校验和] 。

详细介绍请参见：[VNET](https://fd.io/docs/vpp/master/gettingstarted/developers/vnet.html)

**`TODO`**





# 4. VPP Wiki，Doxygen和其他链接

* [FD.io主站点](https://fd.io/docs/vpp/master/links/index.html#fd-io-main-site)
* [VPP Wiki](https://fd.io/docs/vpp/master/links/index.html#vpp-wiki)
* [源代码文档（doxygen）](https://fd.io/docs/vpp/master/links/index.html#source-code-documents-doxygen)

**`TODO`**



# 5. 用例

* [带容器的VPP](https://fd.io/docs/vpp/master/usecases/containers.html)
* [具有Iperf3和TRex的VPP](https://fd.io/docs/vpp/master/usecases/simpleperf/index.html)
* [带有虚拟机的FD.io VPP](https://fd.io/docs/vpp/master/usecases/vhost/index.html)
* [带有VMware / Vmxnet3的VPP](https://fd.io/docs/vpp/master/usecases/vmxnet3.html)
* [带有FD.io VPP的访问控制列表（ACL）](https://fd.io/docs/vpp/master/usecases/acls.html)
* [云中的VPP](https://fd.io/docs/vpp/master/usecases/vppcloud.html)
* [使用VPP作为家庭网关](https://fd.io/docs/vpp/master/usecases/homegateway.html)
* [Contiv / VPP](https://fd.io/docs/vpp/master/usecases/contiv/index.html)
* [网络模拟器插件](https://fd.io/docs/vpp/master/usecases/networksim.html)
* [构建VPP Web应用程序](https://fd.io/docs/vpp/master/usecases/webapp.html)
* [基于容器的网络仿真](https://fd.io/docs/vpp/master/usecases/container_test.html)

**`TODO`**

# 6. 发行功能

网站发行版最高为`19.08.`，我在`10.170.7.166`上安装的是`20.05`.

* [VPP版本19.08的功能](https://fd.io/docs/vpp/master/featuresbyrelease/vpp1908.html)
* VPP版本19.04的功能
* VPP版本19.01的功能


**`TODO`**

# 7. [故障排除](https://fd.io/docs/vpp/master/troubleshooting/index.html)
本章介绍了用于解决和诊断FD.io VPP实现问题的许多技术中的一些。

**`TODO`**

# 8. 参考

* [有用的调试CLI](https://fd.io/docs/vpp/master/reference/cmdreference/index.html)
* [虚拟机与游民](https://fd.io/docs/vpp/master/reference/vppvagrant/index.html)
* [阅读文档](https://fd.io/docs/vpp/master/reference/readthedocs/index.html)
* [Github仓库](https://fd.io/docs/vpp/master/reference/github/index.html)


**`TODO`**








